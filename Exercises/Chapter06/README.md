# ç¬¬å…­ç« ï¼šæ€§èƒ½æ–¹é¢çš„è€ƒè™‘

ã€ŠProgramming Massively Parallel Processorsã€‹ç¬¬å››ç‰ˆ - å­¦ä¹ ç¬”è®°ä¸ç»ƒä¹ 

## ğŸ“š å­¦ä¹ å†…å®¹

æœ¬ç« ç³»ç»Ÿæ¢³ç† GPU æ€§èƒ½ä¼˜åŒ–æŠ€æœ¯ï¼š

- å†…å­˜åˆå¹¶ï¼ˆMemory Coalescingï¼‰
- åˆ†åŒºéœ²è¥ï¼ˆPartition Campingï¼‰
- æŒ‡ä»¤æ··åˆä¸ååé‡
- çº¿ç¨‹ç²—åŒ–ï¼ˆThread Coarseningï¼‰
- èµ„æºå¹³è¡¡ä¸å ç”¨ç‡æƒè¡¡
- Warp æ‰§è¡Œæ•ˆç‡
- æ•°æ®é¢„å–ä¸åŒç¼“å†²

**ç›¸å…³åšå®¢ç¬”è®°**ï¼š[ç¬¬å…­ç« ï¼šæ€§èƒ½æ–¹é¢çš„è€ƒè™‘](https://smarter.xin/posts/220818c3/)

---

## ğŸ’» ä»£ç å®ç°

### Exercise01 - åˆ—ä¸»åºçŸ©é˜µä¹˜æ³•ï¼ˆCorner Turningï¼‰

æœ¬ç»ƒä¹ å®ç°å¯¹åº”å›¾ 6.4 è®¾è®¡çš„çŸ©é˜µä¹˜æ³• kernelï¼Œæ¼”ç¤ºè§’è½¬æ¢ï¼ˆCorner Turningï¼‰æŠ€æœ¯ã€‚

**ä»£ç ä½ç½®**ï¼š`Exercise01/`

**åŠŸèƒ½**ï¼š

- **è¡Œä¸»åº Tiled ç‰ˆæœ¬**ï¼šæ ‡å‡†çš„ Tiled çŸ©é˜µä¹˜æ³•å®ç°
- **åˆ—ä¸»åº Tiled ç‰ˆæœ¬**ï¼šä½¿ç”¨è§’è½¬æ¢æŠ€æœ¯ï¼ŒæŒ‰åˆ—è®¿é—® N çŸ©é˜µä»¥ä¿æŒåˆå¹¶è®¿é—®

**æ ¸å¿ƒä¼˜åŒ–**ï¼š

```cuda
// åˆ—ä¸»åº Tiled çŸ©é˜µä¹˜æ³• Kernelï¼ˆCorner Turningï¼‰
__global__ void TiledMatrixMulKernelColMajor(float* M, float* N, float* P, int m, int n, int o) {
    __shared__ float Mds[TILE_WIDTH][TILE_WIDTH];
    __shared__ float Nds[TILE_WIDTH][TILE_WIDTH];
    
    // ... çœç•¥å˜é‡å®šä¹‰ ...
    
    for (int ph = 0; ph < numTiles; ++ph) {
        // åŠ è½½ Mï¼ˆè¡Œä¸»åºï¼Œæ­£å¸¸è®¿é—®ï¼‰
        Mds[ty][tx] = M[row * n + ph * TILE_WIDTH + tx];
        
        // åŠ è½½ Nï¼ˆåˆ—ä¸»åºï¼šæŒ‰åˆ—è®¿é—®ä»¥ä¿æŒåˆå¹¶ï¼‰
        // N å­˜å‚¨ä¸ºåˆ—ä¸»åºï¼šN[col * n + row]
        Nds[ty][tx] = N[col * n + (ph * TILE_WIDTH + ty)];
        
        __syncthreads();
        for (int k = 0; k < TILE_WIDTH; ++k) {
            Pvalue += Mds[ty][k] * Nds[k][tx];
        }
        __syncthreads();
    }
}
```

#### è¿è¡Œ Exercise01

```bash
cd Exercise01
make
make run
```

#### é¢„æœŸè¾“å‡º

```text
========================================
  ç¬¬å…­ç« ï¼šæ€§èƒ½æ–¹é¢çš„è€ƒè™‘
  Column-Major Matrix Multiplication
========================================

çŸ©é˜µå¤§å°: 4 Ã— 3 Ã— 2

è¡Œä¸»åºçŸ©é˜µä¹˜æ³•ç»“æœ:
åˆ—ä¸»åºçŸ©é˜µä¹˜æ³•ç»“æœ:
âœ… ä¸¤ç§æ–¹æ³•ç»“æœä¸€è‡´ï¼
```

---

### Exercise02 - Thread Coarsening çŸ©é˜µä¹˜æ³•

æœ¬ä»£ç å¯¹æ¯”ä¸‰ç§çŸ©é˜µä¹˜æ³•å®ç°çš„æ€§èƒ½å·®å¼‚ï¼Œæ¼”ç¤º Thread Coarsening ä¼˜åŒ–æŠ€æœ¯ã€‚

**ä»£ç ä½ç½®**ï¼š`Exercise02/`

**ä¸‰ç§å®ç°å¯¹æ¯”**ï¼š

| ç‰ˆæœ¬ | ç‰¹ç‚¹ | ç®—æœ¯å¼ºåº¦ |
| ---- | ---- | -------- |
| æœ´ç´ ç‰ˆæœ¬ | ç›´æ¥å…¨å±€å†…å­˜è®¿é—® | 0.25 OP/B |
| Tiled (32Ã—32) | å…±äº«å†…å­˜ä¼˜åŒ– | 8 OP/B |
| Tiled + CoarseningÃ—4 | æ¯çº¿ç¨‹è®¡ç®— 4 ä¸ªå…ƒç´  | 12.8 OP/B |

**æ ¸å¿ƒä¼˜åŒ–**ï¼š

```cuda
// Thread Coarseningï¼šæ¯ä¸ªçº¿ç¨‹è®¡ç®— COARSE_FACTOR ä¸ªè¾“å‡ºå…ƒç´ 
float Pvalue[COARSE_FACTOR] = {0.0f};  // 4 ä¸ªç´¯åŠ å™¨

for (int ph = 0; ph < numTiles; ++ph) {
    // M çš„ Tile åªåŠ è½½ä¸€æ¬¡
    Mds[ty][tx] = M[row * n + ph * TILE_WIDTH + tx];
    
    // ä½† N çš„ Tile åŠ è½½ COARSE_FACTOR æ¬¡ï¼Œè®¡ç®— 4 ä¸ªè¾“å‡º
    for (int c = 0; c < COARSE_FACTOR; ++c) {
        int col = colStart + c * TILE_WIDTH;
        Nds[ty][tx] = N[(ph * TILE_WIDTH + ty) * o + col];
        __syncthreads();
        
        for (int k = 0; k < TILE_WIDTH; ++k) {
            Pvalue[c] += Mds[ty][k] * Nds[k][tx];
        }
        __syncthreads();
    }
}
```

#### è¿è¡Œ Exercise02

```bash
cd Exercise02
make
make run
```

#### é¢„æœŸè¾“å‡º

```text
========================================
  ç¬¬å…­ç« ï¼šæ€§èƒ½æ–¹é¢çš„è€ƒè™‘
  Thread Coarsening Matrix Multiplication
========================================

çŸ©é˜µå¤§å°: 1024 Ã— 1024 Ã— 1024
æµ‹è¯•è¿­ä»£æ¬¡æ•°: 10
Thread Coarsening Factor: 4

=== æ­£ç¡®æ€§éªŒè¯ ===
âœ… æ‰€æœ‰æ–¹æ³•ç»“æœä¸€è‡´ï¼

=== æ€§èƒ½æµ‹è¯• ===
æœ´ç´ çŸ©é˜µä¹˜æ³•:          57.273 ms
Tiled çŸ©é˜µä¹˜æ³•:        53.636 ms (1.07x vs naive)
Tiled + Coarsening:    48.123 ms (1.19x vs naive, 1.11x vs tiled)
```

---

## ğŸ“– ç»ƒä¹ é¢˜è§£ç­”

### ç»ƒä¹  1

**é¢˜ç›®ï¼š** ç¼–å†™ä¸€ä¸ªå¯¹åº”å›¾ 6.4 è®¾è®¡çš„çŸ©é˜µä¹˜æ³• kernel å‡½æ•°ã€‚

**è§£ç­”ï¼š**

å›¾ 6.4 å±•ç¤ºçš„æ˜¯å¤„ç†åˆ—ä¸»åºï¼ˆColumn-Majorï¼‰çŸ©é˜µçš„ Tiled çŸ©é˜µä¹˜æ³•ã€‚å…³é”®ç‚¹æ˜¯ä½¿ç”¨**è§’è½¬æ¢ï¼ˆCorner Turningï¼‰**æŠ€æœ¯ï¼šä¸æŒ‰è¡Œè®¿é—® N çŸ©é˜µï¼ˆä¼šå¯¼è‡´éåˆå¹¶è®¿é—®ï¼‰ï¼Œè€Œæ˜¯æŒ‰åˆ—è®¿é—®ä»¥ä¿æŒåˆå¹¶è®¿é—®ï¼Œç„¶ååœ¨å…±äº«å†…å­˜ä¸­é‡æ–°æ’åˆ—æ•°æ®ã€‚

```cuda
__global__ void TiledMatrixMulKernelColMajorOrder(float *M, float *N, float *P, 
                                                   int m, int n, int o) {
    // è§’è½¬æ¢ï¼šæŒ‰åˆ—è®¿é—® N çŸ©é˜µï¼ˆåˆå¹¶è®¿é—®ï¼‰
    // å…±äº«å†…å­˜ç”¨äºé‡æ’æ•°æ®
    __shared__ float Mds[TILE_WIDTH][TILE_WIDTH];
    __shared__ float Nds[TILE_WIDTH][TILE_WIDTH];

    int by = blockIdx.y;
    int bx = blockIdx.x;
    int ty = threadIdx.y;
    int tx = threadIdx.x;

    int row = by * TILE_WIDTH + ty;
    int col = bx * TILE_WIDTH + tx;

    float PValue = 0;
    for (int ph = 0; ph < (n + TILE_WIDTH - 1) / TILE_WIDTH; ph++) {
        // åŠ è½½ Mï¼ˆè¡Œä¸»åºï¼Œæ­£å¸¸è®¿é—®ï¼‰
        if (row < m && (ph * TILE_WIDTH + tx) < n)
            Mds[ty][tx] = M[row * n + ph * TILE_WIDTH + tx];
        else
            Mds[ty][tx] = 0.0f;

        // åŠ è½½ Nï¼ˆåˆ—ä¸»åºï¼šæŒ‰åˆ—è®¿é—®ä»¥ä¿æŒåˆå¹¶ï¼‰
        // N åœ¨å†…å­˜ä¸­æ˜¯åˆ—ä¸»åºå­˜å‚¨ï¼šN[col][row] = N[col * n + row]
        if ((ph * TILE_WIDTH + ty) < n && (col < o))
            Nds[ty][tx] = N[col * n + (ph * TILE_WIDTH + ty)];
        else
            Nds[ty][tx] = 0.0f;

        __syncthreads();
        
        for (int k = 0; k < TILE_WIDTH; k++) {
            PValue += Mds[ty][k] * Nds[k][tx];
        }
        __syncthreads();
    }
    
    if (row < m && col < o)
        P[row * o + col] = PValue;
}
```

**å…³é”®ç‚¹**ï¼š

- `N[col * n + (ph * TILE_WIDTH + ty)]`ï¼šæŒ‰åˆ—è®¿é—® Nï¼Œç›¸é‚»çº¿ç¨‹è®¿é—®ç›¸é‚»å†…å­˜åœ°å€
- å…±äº«å†…å­˜ `Nds` å­˜å‚¨åï¼Œè®¡ç®—æ—¶æŒ‰æ­£å¸¸æ–¹å¼è®¿é—®

---

### ç»ƒä¹  2

**é¢˜ç›®ï¼š** å¯¹äº Tiled çŸ©é˜µä¹˜æ³•ï¼Œåœ¨ BLOCK_SIZE çš„å¯èƒ½å–å€¼èŒƒå›´å†…ï¼Œå“ªäº›å€¼èƒ½å®Œå…¨é¿å…å¯¹å…¨å±€å†…å­˜çš„éåˆå¹¶è®¿é—®ï¼Ÿï¼ˆåªè€ƒè™‘æ–¹å½¢å—ï¼‰

**è§£ç­”ï¼š** **BLOCK_SIZE å¿…é¡»æ˜¯ 32 çš„å€æ•°ï¼ˆ32ã€64 ç­‰ï¼‰**

**åˆ†æ**ï¼š

åˆå¹¶è®¿é—®è¦æ±‚ Warp ä¸­çš„ 32 ä¸ªè¿ç»­çº¿ç¨‹è®¿é—®è¿ç»­çš„å†…å­˜åœ°å€ã€‚

- å¦‚æœ BLOCK_SIZE < 32ï¼Œä¸€ä¸ª Warp ä¼šè·¨è¶Šå¤šè¡Œ
- ä¾‹å¦‚ BLOCK_SIZE = 16ï¼šWarp çš„çº¿ç¨‹ 0-15 è®¿é—®ç¬¬ 0 è¡Œï¼Œçº¿ç¨‹ 16-31 è®¿é—®ç¬¬ 1 è¡Œ
- è¿™å¯¼è‡´éƒ¨åˆ†è®¿é—®æ˜¯éåˆå¹¶çš„

**éªŒè¯**ï¼š

| BLOCK_SIZE | Warp åˆ’åˆ† | åˆå¹¶æƒ…å†µ |
| ---------- | --------- | -------- |
| 16 | 1 ä¸ª Warp è·¨ 2 è¡Œ | âŒ éåˆå¹¶ |
| 32 | 1 ä¸ª Warp = 1 è¡Œ | âœ… å®Œå…¨åˆå¹¶ |
| 64 | 2 ä¸ª Warp = 2 è¡Œ | âœ… å®Œå…¨åˆå¹¶ |

**å®è·µé™åˆ¶**ï¼š

- å…±äº«å†…å­˜å¤§å°é™åˆ¶é€šå¸¸ä½¿ BLOCK_SIZE > 64 ä¸å¯è¡Œ
- 32 æ˜¯æœ€å¸¸ç”¨çš„é€‰æ‹©

---

### ç»ƒä¹  3

**é¢˜ç›®ï¼š** è€ƒè™‘ä»¥ä¸‹ CUDA kernelï¼Œåˆ¤æ–­æ¯ä¸ªå†…å­˜è®¿é—®æ˜¯åˆå¹¶çš„ã€éåˆå¹¶çš„ã€è¿˜æ˜¯ä¸é€‚ç”¨åˆå¹¶æ¦‚å¿µï¼š

```cuda
__global__ void foo_kernel(float* a, float* b, float* c, float* d, float* e) {
    unsigned int i = blockIdx.x*blockDim.x + threadIdx.x;
    __shared__ float a_s[256];
    __shared__ float bc_s[4*256];
    a_s[threadIdx.x] = a[i];                              // ç¬¬ 5 è¡Œ
    for(unsigned int j = 0; j < 4; ++j) {
        bc_s[j*256 + threadIdx.x] = 
            b[j*blockDim.x*gridDim.x + i] + c[i*4 + j];   // ç¬¬ 7 è¡Œ
    }
    __syncthreads();
    d[i + 8] = a_s[threadIdx.x];                          // ç¬¬ 10 è¡Œ
    e[i*8] = bc_s[threadIdx.x*4];                         // ç¬¬ 11 è¡Œ
}
```

**è§£ç­”ï¼š**

#### a. ç¬¬ 5 è¡Œè®¿é—®æ•°ç»„ a

**è§£ç­”ï¼š** âœ… **åˆå¹¶è®¿é—®**

`a[blockIdx.x*blockDim.x + threadIdx.x]`ï¼šç›¸é‚»çº¿ç¨‹çš„ `threadIdx.x` è¿ç»­ï¼Œè®¿é—®è¿ç»­å†…å­˜åœ°å€ã€‚

---

#### b. ç¬¬ 5 è¡Œè®¿é—®æ•°ç»„ a_s

**è§£ç­”ï¼š** âšª **ä¸é€‚ç”¨**

`a_s` æ˜¯å…±äº«å†…å­˜ï¼Œåˆå¹¶è®¿é—®æ¦‚å¿µåªé€‚ç”¨äºå…¨å±€å†…å­˜ã€‚

---

#### c. ç¬¬ 7 è¡Œè®¿é—®æ•°ç»„ b

**è§£ç­”ï¼š** âœ… **åˆå¹¶è®¿é—®**

`b[j*blockDim.x*gridDim.x + blockIdx.x*blockDim.x + threadIdx.x]`ï¼šå¯¹äºå›ºå®šçš„ jï¼Œç›¸é‚»çº¿ç¨‹è®¿é—®è¿ç»­åœ°å€ã€‚

---

#### d. ç¬¬ 7 è¡Œè®¿é—®æ•°ç»„ c

**è§£ç­”ï¼š** âŒ **éåˆå¹¶è®¿é—®**

`c[(blockIdx.x*blockDim.x + threadIdx.x)*4 + j]`ï¼šç›¸é‚»çº¿ç¨‹ä¹‹é—´è·³è·ƒ 4 ä¸ªå…ƒç´ ï¼Œæ­¥é•¿ä¸º 4ã€‚

---

#### e. ç¬¬ 7 è¡Œè®¿é—®æ•°ç»„ bc_s

**è§£ç­”ï¼š** âšª **ä¸é€‚ç”¨**

`bc_s` æ˜¯å…±äº«å†…å­˜ã€‚

---

#### f. ç¬¬ 10 è¡Œè®¿é—®æ•°ç»„ a_s

**è§£ç­”ï¼š** âšª **ä¸é€‚ç”¨**

`a_s` æ˜¯å…±äº«å†…å­˜ã€‚

---

#### g. ç¬¬ 10 è¡Œè®¿é—®æ•°ç»„ d

**è§£ç­”ï¼š** âœ… **åˆå¹¶è®¿é—®**

`d[blockIdx.x*blockDim.x + threadIdx.x + 8]`ï¼šç›¸é‚»çº¿ç¨‹è®¿é—®è¿ç»­åœ°å€ï¼ˆåç§» 8 ä¸å½±å“åˆå¹¶ï¼‰ã€‚

---

#### h. ç¬¬ 11 è¡Œè®¿é—®æ•°ç»„ bc_s

**è§£ç­”ï¼š** âšª **ä¸é€‚ç”¨**

`bc_s` æ˜¯å…±äº«å†…å­˜ã€‚

---

#### i. ç¬¬ 11 è¡Œè®¿é—®æ•°ç»„ e

**è§£ç­”ï¼š** âŒ **éåˆå¹¶è®¿é—®**

`e[(blockIdx.x*blockDim.x + threadIdx.x)*8]`ï¼šç›¸é‚»çº¿ç¨‹ä¹‹é—´è·³è·ƒ 8 ä¸ªå…ƒç´ ï¼Œæ¯ä¸ªçº¿ç¨‹è®¿é—®ä¸åŒçš„å†…å­˜æ®µã€‚

---

### ç»ƒä¹  4

**é¢˜ç›®ï¼š** è®¡ç®—ä»¥ä¸‹çŸ©é˜µä¹˜æ³• kernel çš„æµ®ç‚¹è¿ç®—ä¸å…¨å±€å†…å­˜è®¿é—®æ¯”ï¼ˆOP/Bï¼‰ï¼š

å‡è®¾çŸ©é˜µ M å¤§å°ä¸º (m, n)ï¼ŒçŸ©é˜µ N å¤§å°ä¸º (n, o)ï¼Œä½¿ç”¨ float32ï¼ˆ4 å­—èŠ‚ï¼‰ã€‚

---

#### a. ç¬¬ä¸‰ç« çš„ç®€å• kernelï¼Œæ— ä¼˜åŒ–

**è§£ç­”ï¼š** **0.25 OP/B**

**åˆ†æ**ï¼š

å¯¹äºç»“æœçŸ©é˜µçš„æ¯ä¸ªå…ƒç´ ï¼š

- åŠ è½½ M çš„ä¸€è¡Œï¼šn æ¬¡å†…å­˜è¯»å–
- åŠ è½½ N çš„ä¸€åˆ—ï¼šn æ¬¡å†…å­˜è¯»å–
- æ‰§è¡Œä¹˜æ³•ï¼šn æ¬¡
- æ‰§è¡ŒåŠ æ³•ï¼šn-1 â‰ˆ n æ¬¡

```text
å†…å­˜è®¿é—®: 2n Ã— 4 bytes = 8n bytes
æµ®ç‚¹è¿ç®—: 2n (n æ¬¡ä¹˜æ³• + n æ¬¡åŠ æ³•)
æ¯”å€¼: 2n / 8n = 0.25 OP/B
```

---

#### b. ç¬¬äº”ç« ä½¿ç”¨ 32Ã—32 Tile çš„ kernel

**è§£ç­”ï¼š** **8 OP/B**

**åˆ†æ**ï¼š

ä½¿ç”¨ Tiling åï¼Œæ¯ä¸ªçº¿ç¨‹åªéœ€ä»å…¨å±€å†…å­˜åŠ è½½ n/32 ä¸ªå…ƒç´ ï¼ˆM å’Œ N å„ n/32ï¼‰ï¼š

- åŒä¸€ Tile è¢« 32 ä¸ªçº¿ç¨‹å…±äº«ä½¿ç”¨
- æ¯ä¸ªå…ƒç´ ä»å…¨å±€å†…å­˜åªè¯» 1 æ¬¡ï¼Œåœ¨å…±äº«å†…å­˜è¢«ä½¿ç”¨ 32 æ¬¡

```text
å†…å­˜è®¿é—®: 2 Ã— (n/32) Ã— 4 bytes = n/4 bytes
æµ®ç‚¹è¿ç®—: 2n
æ¯”å€¼: 2n / (n/4) = 8 OP/B
```

ç›¸æ¯”æœ´ç´ ç‰ˆæœ¬æå‡ **32 å€**ã€‚

---

#### c. æœ¬ç« ä½¿ç”¨ 32Ã—32 Tile + Thread Coarsening (factor=4) çš„ kernel

**è§£ç­”ï¼š** **12.8 OP/B**

**åˆ†æ**ï¼š

Thread Coarsening è®©æ¯ä¸ªçº¿ç¨‹è®¡ç®— 4 ä¸ªè¾“å‡ºå…ƒç´ ï¼š

- M çš„ Tile è¢«å¤ç”¨ 4 æ¬¡ï¼šn/32/4 = n/128 æ¬¡åŠ è½½
- N çš„ Tile æ­£å¸¸åŠ è½½ï¼šn/32 æ¬¡åŠ è½½
- è®¡ç®—é‡ä¸å˜ï¼š2n æ“ä½œ

```text
å†…å­˜è®¿é—®: (n/128 + n/32) Ã— 4 bytes = (n/128 + 4n/128) Ã— 4 = 5n/32 bytes
æµ®ç‚¹è¿ç®—: 2n
æ¯”å€¼: 2n / (5n/32) = 2n Ã— 32 / 5n = 12.8 OP/B
```

ç›¸æ¯” Tiled ç‰ˆæœ¬æå‡ **1.6 å€**ã€‚

---

## ğŸ”§ å¼€å‘ç¯å¢ƒ

- **CUDA Toolkit**: 11.0 æˆ–æ›´é«˜ç‰ˆæœ¬
- **ç¼–è¯‘å™¨**: GCC 7.5+ / Visual Studio 2019+ + NVCC
- **GPU**: æ”¯æŒ CUDA çš„ NVIDIA æ˜¾å¡ï¼ˆè®¡ç®—èƒ½åŠ› 3.5+ï¼‰

## ğŸ’¡ å­¦ä¹ å»ºè®®

1. **ä¼˜å…ˆä¿è¯åˆå¹¶è®¿é—®**ï¼šæ£€æŸ¥å…¨å±€å†…å­˜è®¿é—®æ¨¡å¼
2. **ä½¿ç”¨ Profiler**ï¼š`ncu` æ¯”çŒœæµ‹æ›´æœ‰æ•ˆ
3. **æƒè¡¡å ç”¨ç‡**ï¼šè®¡ç®—å¯†é›†å‹å¯æ¥å—ä½å ç”¨ç‡
4. **Grid-stride loop**ï¼šçµæ´»å¤„ç†ä»»æ„å¤§å°æ•°æ®
5. **å®æµ‹éªŒè¯**ï¼šä¸åŒ GPU æ€§èƒ½ç‰¹æ€§ä¸åŒ

## ğŸš€ ä¸‹ä¸€æ­¥

å®Œæˆæœ¬ç« å­¦ä¹ åï¼Œç»§ç»­å­¦ä¹ ï¼š

- ç¬¬ä¸ƒç« ï¼šå·ç§¯
- ç¬¬å…«ç« ï¼šæ¨¡æ¿
- ç¬¬ä¹ç« ï¼šå¹¶è¡Œç›´æ–¹å›¾

---

## ğŸ“š å‚è€ƒèµ„æ–™

- PMPP ç¬¬å››ç‰ˆ Chapter 6
- [ç¬¬å…­ç« ï¼šæ€§èƒ½æ–¹é¢çš„è€ƒè™‘](https://smarter.xin/posts/220818c3/)

**å­¦ä¹ æ„‰å¿«ï¼** ğŸ“
