# 第四章：计算架构和调度

《Programming Massively Parallel Processors》第四版 - 学习笔记与练习

## 📚 学习内容

本章深入介绍 GPU 硬件架构和执行模型：

- GPU 架构概览（SM、CUDA 核心、寄存器、共享内存）
- Warp：32 线程的执行单位
- SIMT 执行模型
- 控制流发散和性能影响
- 延迟隐藏机制
- 占用率（Occupancy）计算
- 资源限制和优化策略

**相关博客笔记**：[第四章：计算架构和调度](https://smarter.xin/posts/bd5d1d6/)

---

## 💻 代码实现

### Exercise01 - 设备属性查询

本章主要是理论内容，代码部分仅包含设备属性查询，用于了解 GPU 硬件规格。

**代码位置**：`Exercise01/`

**功能**：查询并打印 CUDA 设备的详细属性，包括：

- 计算能力、SM 数量
- 内存配置（全局、共享、常量、L2 缓存）
- Warp 大小、每块最大线程数
- 网格和块的维度限制
- 时钟频率和内存带宽

#### 运行 Exercise01

```bash
cd Exercise01
make
make run
```

#### 预期输出

```text
检测到 1 个 CUDA 设备
===================================================

设备 0: "NVIDIA GeForce RTX 4090"
---------------------------------------------------
  计算能力:                      8.9

  【内存信息】
  全局内存总量:                  24.00 GB
  常量内存总量:                  65536 bytes (64.00 KB)
  每块共享内存:                  49152 bytes (48.00 KB)
  ...

  【SM (流式多处理器) 信息】
  多处理器 (SM) 数量:            128
  每个 SM 最大线程数:            1536
  ...
```

---

## 📖 练习题解答

### 练习 1

**题目：** 考虑以下 CUDA kernel 和调用它的主机函数：

```cuda
01 __global__ void foo_kernel(int* a, int* b) {
02     unsigned int i = blockIdx.x*blockDim.x + threadIdx.x;
03     if(threadIdx.x < 40 || threadIdx.x >= 104) {
04         b[i] = a[i] + 1;
05     }
06     if(i%2 == 0) {
07         a[i] = b[i]*2;
08     }
09     for(unsigned int j = 0; j < 5 - (i%3); ++j) {
10         b[i] += j;
11     }
12 }
13 void foo(int* a_d, int* b_d) {
14     unsigned int N = 1024;
15     foo_kernel <<<(N + 128 - 1)/128, 128>>>(a_d, b_d);
16 }
```

---

**a. 每个块有多少个 warp？**

**解答：** `128 / 32 = 4` 个 warp

每个块有 128 个线程（第二个启动参数），每个 warp 包含 32 个线程。

---

**b. 网格中有多少个 warp？**

**解答：** `8 × 4 = 32` 个 warp

- 块数：`(1024 + 128 - 1) / 128 = 8` 个块
- 每块 4 个 warp
- 总计：`8 × 4 = 32` 个 warp

---

**c. 对于第 04 行的语句：**

**i. 网格中有多少个 warp 是活跃的？**

**解答：** `3 × 8 = 24` 个活跃 warp

分析每个块中的 4 个 warp：

- **Warp 0**（线程 0-31）：全部满足 `threadIdx.x < 40`，活跃
- **Warp 1**（线程 32-63）：线程 32-39 满足条件，部分活跃
- **Warp 2**（线程 64-95）：无线程满足条件，**不活跃**
- **Warp 3**（线程 96-127）：线程 104-127 满足 `threadIdx.x >= 104`，部分活跃

每块 3 个活跃 warp，共 `3 × 8 = 24` 个。

---

**ii. 网格中有多少个 warp 是发散的？**

**解答：** `2 × 8 = 16` 个发散 warp

Warp 1 和 Warp 3 是发散的（部分线程活跃，部分不活跃）。

---

**iii. Block 0 的 Warp 0 的 SIMD 效率是多少？**

**解答：** `32/32 = 100%`

32 个线程全部执行。

---

**iv. Block 0 的 Warp 1 的 SIMD 效率是多少？**

**解答：** `8/32 = 25%`

Warp 1 覆盖线程 32-63，只有线程 32-39（共 8 个）满足 `threadIdx.x < 40`。

---

**v. Block 0 的 Warp 3 的 SIMD 效率是多少？**

**解答：** `24/32 = 75%`

Warp 3 覆盖线程 96-127，线程 104-127（共 24 个）满足 `threadIdx.x >= 104`。

---

**d. 对于第 07 行的语句：**

**i. 网格中有多少个 warp 是活跃的？**

**解答：** `32` 个（全部活跃）

条件 `i % 2 == 0` 使每个 warp 中一半线程活跃，所以所有 warp 都会执行。

---

**ii. 网格中有多少个 warp 是发散的？**

**解答：** `32` 个（全部发散）

每个 warp 中奇偶线程各占一半，全部发散。

---

**iii. Block 0 的 Warp 0 的 SIMD 效率是多少？**

**解答：** `16/32 = 50%`

只有偶数线程（0, 2, 4, ..., 30）执行，共 16 个。

---

**e. 对于第 09-11 行的循环：**

`i % 3` 的值为 0、1、2，对应循环次数分别为 5、4、3 次。

**i. 有多少次迭代没有发散？**

**解答：** `3` 次（第 0、1、2 次迭代）

所有 1024 个线程都至少执行 3 次迭代，这 3 次没有发散。

---

**ii. 有多少次迭代有发散？**

**解答：** `2` 次（第 3、4 次迭代）

- 第 3 次迭代：只有 `i % 3 != 2` 的线程执行（约 2/3）
- 第 4 次迭代：只有 `i % 3 == 0` 的线程执行（约 1/3）

---

### 练习 2

**题目：** 对于向量加法，假设向量长度为 2000，每个线程计算一个输出元素，线程块大小为 512。网格中有多少个线程？

**解答：** `2048` 个线程

- 需要的最少块数：`⌈2000 / 512⌉ = 4` 个块
- 总线程数：`4 × 512 = 2048` 个线程

（多出的 48 个线程会因边界检查而跳过计算）

---

### 练习 3

**题目：** 对于上一题，有多少个 warp 会因向量长度边界检查而发散？

**解答：** `1` 个发散 warp

- 共 `2048 / 32 = 64` 个 warp
- 覆盖线程 2016-2047 的 warp 完全跳过（不活跃）
- 覆盖线程 1984-2015 的 warp 是发散的：
  - 线程 1984-1999（16 个）有数据处理
  - 线程 2000-2015（16 个）跳过

---

### 练习 4

**题目：** 考虑一个有 8 个线程的假设块，在到达屏障之前执行一段代码。各线程执行该段代码所需的时间（微秒）分别为：2.0, 2.3, 3.0, 2.8, 2.4, 1.9, 2.6, 2.9。它们剩余时间都在等待屏障。线程等待屏障的时间占总执行时间的百分比是多少？

**解答：** `16.67%`

**计算过程：**

- 最慢线程：3.0 微秒
- 各线程等待时间：`(3.0-2.0) + (3.0-2.3) + 0 + (3.0-2.8) + (3.0-2.4) + (3.0-1.9) + (3.0-2.6) + (3.0-2.9)`
  `= 1.0 + 0.7 + 0.0 + 0.2 + 0.6 + 1.1 + 0.4 + 0.1 = 4.1` 微秒
- 总执行时间：`8 × 3.0 = 24.0` 微秒
- 等待百分比：`4.1 / 24.0 ≈ 17.08%`（原题解为 16%）

---

### 练习 5

**题目：** 一位 CUDA 程序员说，如果他们启动的 kernel 每个块只有 32 个线程，就可以省略需要屏障同步的地方的 `__syncthreads()` 指令。你认为这是个好主意吗？请解释。

**解答：**

**理论上可行，但实践中不推荐。**

**原因分析：**

1. **理论基础**：同一 warp 内的 32 个线程以 SIMT 方式执行，指令级天然同步

2. **实际风险**：
   - 涉及内存操作时，底层硬件可能有延迟，不保证顺序
   - 编译器优化可能重排指令
   - 不同架构行为可能不同

3. **兼容性问题**：
   - NVIDIA 不保证 warp 大小永远是 32
   - 未来架构可能改变执行模型

4. **最佳实践**：
   - 始终使用 `__syncthreads()` 确保正确性
   - 代码更易维护和移植

---

### 练习 6

**题目：** 如果 CUDA 设备的 SM 最多支持 1536 个线程和 4 个线程块，以下哪种块配置能使 SM 中的线程数最多？

- a. 每块 128 个线程
- b. 每块 256 个线程
- c. 每块 512 个线程
- d. 每块 1024 个线程

**解答：** **c. 每块 512 个线程**

**计算过程：**

| 配置     | 计算                                    | SM 中线程数 |
| -------- | --------------------------------------- | ----------- |
| a. 128   | `min(4, 1536/128) × 128 = 4 × 128`      | 512         |
| b. 256   | `min(4, 1536/256) × 256 = 4 × 256`      | 1024        |
| c. 512   | `min(4, 1536/512) × 512 = 3 × 512`      | **1536**    |
| d. 1024  | `min(4, 1536/1024) × 1024 = 1 × 1024`   | 1024        |

512 个线程/块时，可以放 3 个块，总计 1536 个线程，达到 SM 上限。

---

### 练习 7

**题目：** 假设设备每 SM 最多支持 64 个块和 2048 个线程。判断以下配置是否可行，如果可行，计算占用率。

**解答：**

| 配置                  | 线程数 | 是否可行  | 占用率    |
| --------------------- | ------ | --------- | --------- |
| a. 8 块 × 128 线程    | 1024   | ✅ 可行   | 50%       |
| b. 16 块 × 64 线程    | 1024   | ✅ 可行   | 50%       |
| c. 32 块 × 32 线程    | 1024   | ✅ 可行   | 50%       |
| d. 64 块 × 32 线程    | 2048   | ✅ 可行   | **100%**  |
| e. 32 块 × 64 线程    | 2048   | ✅ 可行   | **100%**  |

所有配置都满足 ≤64 块和 ≤2048 线程的限制。

---

### 练习 8

**题目：** 考虑一个 GPU，限制为：每 SM 2048 线程、32 块、65536 个寄存器。判断以下 kernel 能否达到完全占用率，如果不能，指出限制因素。

---

#### a. 每块 128 线程，每线程 30 个寄存器

**解答：** ✅ **可达到完全占用率 (100%)**

- 块大小限制：`2048 / 128 = 16` 块（< 32，满足）
- 寄存器限制：`128 × 30 = 3840` 寄存器/块 → `65536 / 3840 = 17` 块
- 实际块数：`min(16, 17) = 16` 块
- 线程数：`16 × 128 = 2048` = 完全占用

---

#### b. 每块 32 线程，每线程 29 个寄存器

**解答：** ❌ **占用率 50%**，限制因素：**块数限制**

- 块大小限制：`2048 / 32 = 64` 块，但 SM 限制 32 块
- 寄存器限制：`32 × 29 = 928` 寄存器/块 → `65536 / 928 = 70` 块 > 32
- 实际块数：`32` 块（受块数限制）
- 线程数：`32 × 32 = 1024` → 占用率 50%

---

#### c. 每块 256 线程，每线程 34 个寄存器

**解答：** ❌ **占用率 87.5%**，限制因素：**寄存器限制**

- 块大小限制：`2048 / 256 = 8` 块（< 32，满足）
- 寄存器限制：`256 × 34 = 8704` 寄存器/块 → `65536 / 8704 = 7` 块
- 实际块数：`min(8, 7) = 7` 块（受寄存器限制）
- 线程数：`7 × 256 = 1792` → 占用率 `1792/2048 = 87.5%`

---

### 练习 9

**题目：** 一位学生说他们能够使用 32×32 线程块的矩阵乘法 kernel 来乘两个 1024×1024 的矩阵。该学生使用的 CUDA 设备每块最多支持 512 个线程，每 SM 最多 8 个块。学生还说每个线程计算结果矩阵的一个元素。你的反应是什么？为什么？

**解答：**

**这是不可能的配置，学生的描述存在矛盾。**

**分析：**

1. **结果矩阵元素数**：`1024 × 1024 = 1,048,576` 个元素

2. **学生声称的配置**：
   - 32×32 = 1024 线程/块
   - 但设备限制每块最多 512 个线程！

3. **矛盾点**：32×32 = 1024 > 512，这个块配置本身就超出了设备限制

4. **正确配置示例**：
   - 如果使用 16×16 = 256 线程/块
   - 需要 `1024/16 × 1024/16 = 64 × 64 = 4096` 个块
   - 总线程：`4096 × 256 = 1,048,576`，刚好覆盖所有元素

**注**：每 SM 块数（8 个）对单次 kernel 调用的可行性无影响，只影响并行度和占用率。

---

## 🔧 开发环境

- **CUDA Toolkit**: 11.0 或更高版本
- **编译器**: GCC 7.5+ / Visual Studio 2019+ + NVCC
- **GPU**: 支持 CUDA 的 NVIDIA 显卡（计算能力 3.5+）

## 💡 学习建议

1. **运行设备查询**：了解你的 GPU 具体参数
2. **理解 Warp**：这是 GPU 执行的核心概念
3. **分析发散**：练习识别代码中的分支发散
4. **计算占用率**：结合寄存器、共享内存、块大小综合考虑
5. **使用 Profiler**：`ncu` 工具比猜测更有效

## 🚀 下一步

完成本章学习后，继续学习：

- 第五章：内存架构和数据局部性
- 第六章：性能考虑
- 第七章：卷积

---

## 📚 参考资料

- PMPP 第四版 Chapter 4
- [第四章：计算架构和调度](https://smarter.xin/posts/bd5d1d6/)

**学习愉快！** 🎓
