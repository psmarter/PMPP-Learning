# ç¬¬åå››ç« ï¼šç¨€ç–çŸ©é˜µè®¡ç®—

ã€ŠProgramming Massively Parallel Processorsã€‹ç¬¬å››ç‰ˆ - å­¦ä¹ ç¬”è®°ä¸ç»ƒä¹ 

## ğŸ“š å­¦ä¹ å†…å®¹

æœ¬ç« ç³»ç»Ÿæ¢³ç†ç¨€ç–çŸ©é˜µå­˜å‚¨æ ¼å¼å’Œ SpMVï¼ˆç¨€ç–çŸ©é˜µ-å‘é‡ä¹˜æ³•ï¼‰çš„ CUDA å®ç°ï¼š

- COOã€CSRã€ELLã€JDS ç­‰å­˜å‚¨æ ¼å¼
- å„æ ¼å¼çš„ SpMV å¹¶è¡Œå®ç°
- æ ¼å¼è½¬æ¢ï¼ˆCOO â†’ CSRï¼‰
- æ··åˆæ ¼å¼ä¼˜åŒ–ï¼ˆELL-COOï¼‰

**ç›¸å…³åšå®¢ç¬”è®°**ï¼š[ç¬¬åå››ç« ï¼šç¨€ç–çŸ©é˜µè®¡ç®—](https://smarter.xin/posts/7af84cf7/)

---

## ğŸ’» ä»£ç å®ç°

### Exercise01 - SpMV å®ç°

å®ç°å¤šç§ç¨€ç–æ ¼å¼çš„ SpMV kernelã€‚

**ä»£ç ä½ç½®**ï¼š`Exercise01/`

**å®ç°åˆ—è¡¨**ï¼š

| å®ç° | æ ¼å¼ | ç‰¹ç‚¹ |
| ---- | ---- | ---- |
| `spmv_coo` | COO | åŸå­æ“ä½œç´¯åŠ ï¼Œæœ€ç®€å• |
| `spmv_csr` | CSR | æ¯è¡Œä¸€çº¿ç¨‹ï¼Œæœ€å¸¸ç”¨ |
| `spmv_ell` | ELL | åˆ—ä¸»åºï¼Œåˆå¹¶è®¿é—® |
| `spmv_jds` | JDS | æŒ‰è¡Œé•¿åº¦æ’åºï¼ˆç»ƒä¹ 5ï¼‰ |
| `spmv_hybrid` | ELL-COO | æ··åˆæ ¼å¼ï¼ˆç»ƒä¹ 4ï¼‰ |
| `coo_to_csr` | è½¬æ¢ | ç›´æ–¹å›¾+å‰ç¼€å’Œï¼ˆç»ƒä¹ 3ï¼‰ |

**æ ¸å¿ƒä»£ç **ï¼š

```cuda
// CSR SpMV - æ¯è¡Œä¸€ä¸ªçº¿ç¨‹
__global__ void spmv_csr_kernel(int numRows, const int* rowPtrs, const int* colIdx,
                                 const float* values, const float* x, float* y) {
    int row = blockIdx.x * blockDim.x + threadIdx.x;
    
    if (row < numRows) {
        float sum = 0.0f;
        for (int j = rowPtrs[row]; j < rowPtrs[row + 1]; j++) {
            sum += values[j] * x[colIdx[j]];
        }
        y[row] = sum;
    }
}
```

#### è¿è¡Œ Exercise01

```bash
cd Exercise01
make
make run
```

#### é¢„æœŸè¾“å‡º

```text
================================================================
  ç¬¬åå››ç« ï¼šç¨€ç–çŸ©é˜µè®¡ç®—
  Sparse Matrix-Vector Multiplication (SpMV)
================================================================

é…ç½®:
  çŸ©é˜µå¤§å°: 4 Ã— 4
  éé›¶å…ƒç´ : 8
  ç¨€ç–åº¦: 50.0%

=== æ­£ç¡®æ€§éªŒè¯ ===

1. COO SpMV... âœ… ç»“æœæ­£ç¡®ï¼
2. CSR SpMV... âœ… ç»“æœæ­£ç¡®ï¼
3. ELL SpMV... âœ… ç»“æœæ­£ç¡®ï¼
4. COO to CSR è½¬æ¢ (ç»ƒä¹ 3)... âœ… è½¬æ¢æ­£ç¡®ï¼
5. JDS SpMV (ç»ƒä¹ 5)... âœ… ç»“æœæ­£ç¡®ï¼
6. ELL-COO Hybrid SpMV (ç»ƒä¹ 4)... âœ… ç»“æœæ­£ç¡®ï¼
```

---

## ğŸ“– ç»ƒä¹ é¢˜è§£ç­”

### ç»ƒä¹  1

**é¢˜ç›®ï¼š** å¯¹äºä»¥ä¸‹ç¨€ç–çŸ©é˜µï¼Œåˆ†åˆ«ç”¨ COOã€CSRã€ELL å’Œ JDS æ ¼å¼è¡¨ç¤ºã€‚

![åŸå§‹çŸ©é˜µ](exercise2.png)

**è§£ç­”ï¼š**

**COO æ ¼å¼ï¼š**

![åŸå§‹çŸ©é˜µ](exercise2_coo.png)

**CSR æ ¼å¼ï¼š**

![åŸå§‹çŸ©é˜µ](exercise2_csr.png)

**ELL æ ¼å¼ï¼š**

![åŸå§‹çŸ©é˜µ](exercise2_ell.png)

**JDS æ ¼å¼ï¼š**

![JDSæ ¼å¼](exercise2_jds.png)

---

### ç»ƒä¹  2

**é¢˜ç›®ï¼š** ç»™å®š m è¡Œã€n åˆ—ã€z ä¸ªéé›¶å…ƒç´ çš„ç¨€ç–çŸ©é˜µï¼Œå„æ ¼å¼éœ€è¦å¤šå°‘æ•´æ•°å­˜å‚¨ï¼Ÿ

**è§£ç­”ï¼š**

| æ ¼å¼ | å­˜å‚¨ç©ºé—´ | è¯´æ˜ |
|------|----------|------|
| COO | 3z | rowIdx(z) + colIdx(z) + values(z) |
| CSR | 2z + m + 1 | rowPtrs(m+1) + colIdx(z) + values(z) |
| ELL | 2 Ã— m Ã— K | éœ€è¦çŸ¥é“æœ€å¤§è¡Œé•¿åº¦ K |
| JDS | 2z + m + K + 1 | éœ€è¦çŸ¥é“æœ€å¤§è¡Œé•¿åº¦ K |

æ³¨æ„ï¼šELL å’Œ JDS éœ€è¦é¢å¤–ä¿¡æ¯ï¼ˆæœ€å¤§è¡Œé•¿åº¦ Kï¼‰æ‰èƒ½ç²¾ç¡®è®¡ç®—ã€‚

---

### ç»ƒä¹  3

**é¢˜ç›®ï¼š** ä½¿ç”¨å¹¶è¡Œè®¡ç®—åŸè¯­ï¼ˆç›´æ–¹å›¾ã€å‰ç¼€å’Œï¼‰å®ç° COO åˆ° CSR çš„è½¬æ¢ã€‚

**è§£ç­”ï¼š**

```cuda
// æ­¥éª¤1ï¼šå¹¶è¡Œç›´æ–¹å›¾ - ç»Ÿè®¡æ¯è¡Œå…ƒç´ æ•°
__global__ void computeHistogram(int nnz, int* rowIdx, int* rowPtrs) {
    int i = blockIdx.x * blockDim.x + threadIdx.x;
    if (i < nnz) {
        atomicAdd(&rowPtrs[rowIdx[i] + 1], 1);
    }
}

// æ­¥éª¤2ï¼šå‰ç¼€å’Œ - è®¡ç®—è¡ŒæŒ‡é’ˆ
// ä½¿ç”¨ thrust::exclusive_scan æˆ–è‡ªå®šä¹‰æ‰«æ

// æ­¥éª¤3ï¼šå¤åˆ¶åˆ—ç´¢å¼•å’Œå€¼ï¼ˆå‡è®¾ COO å·²æŒ‰è¡Œæ’åºï¼‰
```

å®Œæ•´å®ç°è§ `solution.cu` ä¸­çš„ `coo_to_csr` å‡½æ•°ã€‚

---

### ç»ƒä¹  4

**é¢˜ç›®ï¼š** å®ç° ELL-COO æ··åˆæ ¼å¼çš„ SpMVï¼ŒELL åœ¨ GPU æ‰§è¡Œï¼ŒCOO æº¢å‡ºéƒ¨åˆ†åœ¨ CPU æ‰§è¡Œã€‚

**è§£ç­”ï¼š**

```cuda
void spmv_hybrid(const ELLMatrix& ellPart, const COOMatrix& cooPart, 
                 const float* d_x, float* d_y) {
    // 1. GPU æ‰§è¡Œ ELL éƒ¨åˆ†
    spmv_ell_kernel<<<...>>>(ellPart, d_x, d_y);
    
    // 2. æ‹·è´éƒ¨åˆ†ç»“æœåˆ° CPU
    cudaMemcpy(h_y, d_y, ...);
    cudaMemcpy(h_x, d_x, ...);
    
    // 3. CPU æ‰§è¡Œ COO æº¢å‡ºéƒ¨åˆ†
    for (int i = 0; i < cooPart.nnz; i++) {
        h_y[cooPart.rowIdx[i]] += cooPart.values[i] * h_x[cooPart.colIdx[i]];
    }
    
    // 4. æ‹·è´å› GPU
    cudaMemcpy(d_y, h_y, ...);
}
```

å®Œæ•´å®ç°è§ `solution.cu` ä¸­çš„ `spmv_hybrid` å‡½æ•°ã€‚

---

### ç»ƒä¹  5

**é¢˜ç›®ï¼š** å®ç° JDS æ ¼å¼çš„å¹¶è¡Œ SpMV kernelã€‚

**è§£ç­”ï¼š**

```cuda
__global__ void spmv_jds_kernel(int numRows, int numTiles, const int* colIdx,
                                 const float* values, const int* rowPerm, 
                                 const int* iterPtr, const float* x, float* y) {
    int tid = blockIdx.x * blockDim.x + threadIdx.x;
    if (tid >= numRows) return;
    
    float sum = 0.0f;
    for (int t = 0; t < numTiles; t++) {
        int idx = iterPtr[t] + tid;
        if (idx < iterPtr[t + 1]) {
            sum += values[idx] * x[colIdx[idx]];
        }
    }
    // æŒ‰åŸå§‹è¡Œé¡ºåºå†™å›
    y[rowPerm[tid]] = sum;
}
```

å®Œæ•´å®ç°è§ `solution.cu` ä¸­çš„ `spmv_jds` å‡½æ•°ã€‚

---

## ğŸ”§ å¼€å‘ç¯å¢ƒ

- **CUDA Toolkit**: 11.0 æˆ–æ›´é«˜ç‰ˆæœ¬
- **ç¼–è¯‘å™¨**: GCC 7.5+ / Visual Studio 2019+ + NVCC
- **GPU**: æ”¯æŒ CUDA çš„ NVIDIA æ˜¾å¡ï¼ˆè®¡ç®—èƒ½åŠ› 3.5+ï¼‰

## ğŸ’¡ å­¦ä¹ å»ºè®®

1. **ç†è§£æ ¼å¼ç‰¹ç‚¹**ï¼šCOO ç®€å•ã€CSR é€šç”¨ã€ELL è§„åˆ™ã€JDS å¹³è¡¡
2. **æƒè¡¡ç©ºé—´å’Œæ€§èƒ½**ï¼šELL å¯èƒ½æµªè´¹ç©ºé—´ä½†è®¿é—®è§„åˆ™
3. **è€ƒè™‘è´Ÿè½½å‡è¡¡**ï¼šè¡Œé•¿åº¦å·®å¼‚å¤§æ—¶éœ€è¦ç‰¹æ®Šå¤„ç†
4. **ç”Ÿäº§ç¯å¢ƒç”¨åº“**ï¼šcuSPARSE æä¾›é«˜åº¦ä¼˜åŒ–çš„å®ç°
5. **æ ¼å¼é€‰æ‹©ç­–ç•¥**ï¼šæ ¹æ®çŸ©é˜µç‰¹å¾é€‰æ‹©æ ¼å¼â€”â€”CSR é€‚åˆé€šç”¨åœºæ™¯ï¼ŒELL é€‚åˆè¡Œé•¿åº¦ç›¸è¿‘çš„çŸ©é˜µï¼Œæ··åˆæ ¼å¼ï¼ˆELL-COOï¼‰é€‚åˆè¡Œé•¿åº¦å·®å¼‚å¤§çš„çŸ©é˜µï¼›ä½¿ç”¨ `cusparseMatDescr_t` æè¿°ç¬¦æŒ‡å®šçŸ©é˜µå±æ€§ï¼ˆå¯¹ç§°æ€§ã€ç¨€ç–æ¨¡å¼ï¼‰ä»¥å¯ç”¨è¿›ä¸€æ­¥ä¼˜åŒ–

## ğŸš€ ä¸‹ä¸€æ­¥

å®Œæˆæœ¬ç« å­¦ä¹ åï¼Œç»§ç»­å­¦ä¹ ï¼š

- ç¬¬åäº”ç« ï¼šå›¾éå†
- ç¬¬åå…­ç« ï¼šæ·±åº¦å­¦ä¹ 
- ç¬¬åä¸ƒç« ï¼šè¿­ä»£ç£å…±æŒ¯æˆåƒé‡å»º

---

## ğŸ“š å‚è€ƒèµ„æ–™

- PMPP ç¬¬å››ç‰ˆ Chapter 14
- [ç¬¬åå››ç« ï¼šç¨€ç–çŸ©é˜µè®¡ç®—](https://smarter.xin/posts/7af84cf7/)

**å­¦ä¹ æ„‰å¿«ï¼** ğŸ“
