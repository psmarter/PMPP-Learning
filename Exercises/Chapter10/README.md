# ç¬¬åç« ï¼šå½’çº¦

ã€ŠProgramming Massively Parallel Processorsã€‹ç¬¬å››ç‰ˆ - å­¦ä¹ ç¬”è®°ä¸ç»ƒä¹ 

## ğŸ“š å­¦ä¹ å†…å®¹

æœ¬ç« ç³»ç»Ÿæ¢³ç†å½’çº¦ï¼ˆReductionï¼‰æ“ä½œåŠå…¶ CUDA ä¼˜åŒ–æŠ€æœ¯ï¼š

- ç®€å•å½’çº¦ä¸æ§åˆ¶åˆ†æ­§
- æ”¶æ•›å½’çº¦ï¼ˆä¼˜åŒ–åˆ†æ­§ï¼‰
- å…±äº«å†…å­˜ä¼˜åŒ–
- åˆ†æ®µå½’çº¦ï¼ˆæ”¯æŒä»»æ„é•¿åº¦ï¼‰
- çº¿ç¨‹ç²—åŒ–ï¼ˆThread Coarseningï¼‰

**ç›¸å…³åšå®¢ç¬”è®°**ï¼š[ç¬¬åç« ï¼šå½’çº¦å’Œæœ€å°åŒ–å‘æ•£](https://smarter.xin/posts/43b40d12/)

---

## ğŸ’» ä»£ç å®ç°

### Exercise01 - å½’çº¦å®ç°

å®ç°å¤šç§å½’çº¦ kernelï¼Œå¯¹åº”ä¹¦ä¸­å›¾10.6ã€10.9ã€10.11ã€10.15ã€‚

**ä»£ç ä½ç½®**ï¼š`Exercise01/`

**å®ç°åˆ—è¡¨**ï¼š

| å®ç° | ä¹¦ä¸­å¯¹åº” | ç‰¹ç‚¹ |
| ---- | -------- | ---- |
| `reduction_sequential` | - | CPUå‚è€ƒå®ç° |
| `reduction_simple` | å›¾10.6 | ç®€å•å½’çº¦ï¼Œåˆ†æ­§ä¸¥é‡ |
| `reduction_convergent` | å›¾10.9 | æ”¶æ•›å½’çº¦ï¼Œæ¶ˆé™¤åˆ†æ­§ |
| `reduction_convergent_reversed` | ç»ƒä¹ 3 | åå‘æ”¶æ•›å½’çº¦ |
| `reduction_shared_memory` | å›¾10.11 | å…±äº«å†…å­˜å½’çº¦ |
| `reduction_segmented` | - | åˆ†æ®µå½’çº¦ï¼Œæ”¯æŒä»»æ„é•¿åº¦ |
| `reduction_coarsened` | å›¾10.15 | çº¿ç¨‹ç²—åŒ–å½’çº¦ |
| `max_reduction_coarsened` | ç»ƒä¹ 4 | æœ€å¤§å€¼å½’çº¦ |

**æ ¸å¿ƒä»£ç **ï¼š

```cuda
// æ”¶æ•›å½’çº¦æ ¸å¿ƒæ€æƒ³ï¼ˆå›¾10.9ï¼‰
__global__ void convergent_sum_reduction_kernel(float* input, float* output) {
    unsigned int i = threadIdx.x;

    for (unsigned int stride = blockDim.x; stride >= 1; stride /= 2) {
        if (threadIdx.x < stride) {
            input[i] += input[i + stride];
        }
        __syncthreads();
    }

    if (threadIdx.x == 0) {
        *output = input[0];
    }
}
```

#### è¿è¡Œ Exercise01

```bash
cd Exercise01
make
make run
```

#### é¢„æœŸè¾“å‡º

```text
================================================================
  ç¬¬åç« ï¼šå½’çº¦
  Reduction Operations - Multiple Implementations
================================================================

=== å°è§„æ¨¡æµ‹è¯•ï¼ˆå• Blockï¼Œ2048 å…ƒç´ ï¼‰===

1. CPU é¡ºåºå½’çº¦... ç»“æœ: 2048.00
2. ç®€å•å½’çº¦ (å›¾10.6)... ç»“æœ: 2048.00 âœ… æ­£ç¡®ï¼
3. æ”¶æ•›å½’çº¦ (å›¾10.9)... ç»“æœ: 2048.00 âœ… æ­£ç¡®ï¼
4. åå‘æ”¶æ•›å½’çº¦ (ç»ƒä¹ 3)... ç»“æœ: 2048.00 âœ… æ­£ç¡®ï¼
5. å…±äº«å†…å­˜å½’çº¦ (å›¾10.11)... ç»“æœ: 2048.00 âœ… æ­£ç¡®ï¼

=== å¤§è§„æ¨¡æµ‹è¯•ï¼ˆå¤š Blockï¼Œ10000000 å…ƒç´ ï¼‰===

6. CPU é¡ºåºå½’çº¦... ç»“æœ: 10000000.00
7. åˆ†æ®µå½’çº¦... ç»“æœ: 10000000.00 âœ… æ­£ç¡®ï¼
8. çº¿ç¨‹ç²—åŒ–å½’çº¦ (å›¾10.15)... ç»“æœ: 10000000.00 âœ… æ­£ç¡®ï¼
```

---

## ğŸ“– ç»ƒä¹ é¢˜è§£ç­”

### ç»ƒä¹  1

**é¢˜ç›®ï¼š** å¯¹äºå›¾10.6çš„ç®€å•å½’çº¦ kernelï¼Œå¦‚æœå…ƒç´ æ•°ä¸º1024ï¼Œwarp å¤§å°ä¸º32ï¼Œç¬¬5æ¬¡è¿­ä»£æ—¶æœ‰å¤šå°‘ä¸ª warp å­˜åœ¨åˆ†æ­§ï¼Ÿ

**è§£ç­”ï¼š**

å›¾10.6 çš„ç®€å•å½’çº¦ kernelï¼š

```cpp
__global__ void simple_sum_reduction_kernel(float* input, float* output){
    unsigned int i = 2 * threadIdx.x;

    for (unsigned int stride = 1; stride <= blockDim.x; stride *= 2){
        if (threadIdx.x % stride == 0){
            input[i] += input[i + stride];
        }
        __syncthreads();
    }

    if (threadIdx.x == 0)
        *output = input[0];
}
```

1024 å…ƒç´ ï¼Œæ¯ä¸ªçº¿ç¨‹å¤„ç†2ä¸ªå…ƒç´ ï¼Œæ‰€ä»¥æœ‰ `1024/2 = 512` ä¸ªçº¿ç¨‹ã€‚

512 çº¿ç¨‹ / 32 = **16 ä¸ª warp**ã€‚

å„è¿­ä»£çš„ strideï¼š

- è¿­ä»£ 1: stride = 1
- è¿­ä»£ 2: stride = 2
- è¿­ä»£ 3: stride = 4
- è¿­ä»£ 4: stride = 8
- è¿­ä»£ 5: stride = 16

ç¬¬5æ¬¡è¿­ä»£æ—¶ï¼Œæ»¡è¶³ `threadIdx.x % 16 == 0` çš„çº¿ç¨‹æ‰§è¡Œï¼šçº¿ç¨‹ 0, 16, 32, 48, ..., 496ã€‚

æ¯ä¸ª warpï¼ˆ32çº¿ç¨‹ï¼‰ä¸­æœ‰2ä¸ªçº¿ç¨‹æ´»è·ƒã€‚ä¾‹å¦‚ï¼š

- Warp 0: çº¿ç¨‹ 0 å’Œ 16 æ´»è·ƒ
- Warp 15: çº¿ç¨‹ 480 å’Œ 496 æ´»è·ƒ

æ‰€æœ‰ **16 ä¸ª warp éƒ½æœ‰æ§åˆ¶åˆ†æ­§**ã€‚

---

### ç»ƒä¹  2

**é¢˜ç›®ï¼š** å¯¹äºå›¾10.9çš„æ”¶æ•›å½’çº¦ kernelï¼Œå¦‚æœå…ƒç´ æ•°ä¸º1024ï¼Œwarp å¤§å°ä¸º32ï¼Œç¬¬5æ¬¡è¿­ä»£æ—¶æœ‰å¤šå°‘ä¸ª warp å­˜åœ¨åˆ†æ­§ï¼Ÿ

**è§£ç­”ï¼š**

å›¾10.9 çš„æ”¶æ•›å½’çº¦ kernelï¼š

```cpp
__global__ void ConvergentSumReductionKernel(float* input, float* output) {
    unsigned int i = threadIdx.x;
    for (unsigned int stride = blockDim.x; stride >= 1; stride /= 2) {
        if (threadIdx.x < stride) {
            input[i] += input[i + stride];
        }
        __syncthreads();
    }
    if(threadIdx.x == 0) {
        *output = input[0];
    }
}
```

åŒæ · 512 çº¿ç¨‹ï¼Œ16 ä¸ª warpã€‚

å„è¿­ä»£çš„ strideï¼š

- è¿­ä»£ 1: stride = 512
- è¿­ä»£ 2: stride = 256
- è¿­ä»£ 3: stride = 128
- è¿­ä»£ 4: stride = 64
- è¿­ä»£ 5: stride = 32

ç¬¬5æ¬¡è¿­ä»£æ—¶ï¼Œåªæœ‰ `threadIdx.x < 32` çš„çº¿ç¨‹æ´»è·ƒï¼Œå³çº¿ç¨‹ 0-31ã€‚

è¿™æ­£å¥½æ˜¯ **1 ä¸ªå®Œæ•´çš„ warp**ï¼ˆWarp 0ï¼‰ï¼Œå…¶ä¸­æ‰€æœ‰çº¿ç¨‹éƒ½æ´»è·ƒï¼Œ**æ— åˆ†æ­§**ã€‚

å…¶ä»– 15 ä¸ª warp å®Œå…¨ä¸æ´»è·ƒï¼Œä¹Ÿæ— åˆ†æ­§ã€‚

ç­”æ¡ˆï¼š**0 ä¸ª warp æœ‰åˆ†æ­§**ã€‚

![10.9 kernel setting visualization](exercise_2_visualization.png)

---

### ç»ƒä¹  3

**é¢˜ç›®ï¼š** ä¿®æ”¹å›¾10.9çš„ kernelï¼Œä½¿ç”¨ä¸‹å›¾æ‰€ç¤ºçš„è®¿é—®æ¨¡å¼ï¼ˆä»å³å‘å·¦æ”¶æ•›ï¼‰ã€‚

![the new kernel visualization](exercise_3_visualization.png)

**è§£ç­”ï¼š**

```cpp
__global__ void convergent_sum_reduction_kernel_reversed(float* input, float* output){
    unsigned int i = threadIdx.x + blockDim.x;
    
    for (unsigned int stride = blockDim.x; stride >= 1; stride /= 2){
        // stride ä¸å˜ï¼Œä½†ä»å³ä¾§ç´¢å¼•
        if (blockDim.x - threadIdx.x <= stride){
            input[i] += input[i - stride];
        }
        __syncthreads();
    }
    
    // ç»“æœåœ¨æœ€åä¸€ä¸ªå…ƒç´ 
    if (threadIdx.x == blockDim.x - 1){
        *output = input[i];
    }
}
```

è¯¥å®ç°å·²åŒ…å«åœ¨ `Exercise01/solution.cu` ä¸­ã€‚

---

### ç»ƒä¹  4

**é¢˜ç›®ï¼š** ä¿®æ”¹å›¾10.15çš„ kernelï¼Œæ‰§è¡Œæœ€å¤§å€¼å½’çº¦è€Œä¸æ˜¯æ±‚å’Œå½’çº¦ã€‚

**è§£ç­”ï¼š**

```cpp
__global__ void CoarsenedMaxReductionKernel(float* input, float* output) {
    __shared__ float input_s[BLOCK_DIM];
    unsigned int segment = COARSE_FACTOR*2*blockDim.x*blockIdx.x;
    unsigned int i = segment + threadIdx.x;
    unsigned int t = threadIdx.x;
    
    float maximum_value = input[i];
    for(unsigned int tile = 1; tile < COARSE_FACTOR*2; ++tile) {
        maximum_value = fmax(maximum_value, input[i + tile*BLOCK_DIM]);
    }
    input_s[t] = maximum_value;

    for (unsigned int stride = blockDim.x/2; stride >= 1; stride /= 2){
        __syncthreads();
        if (t < stride) {
            input_s[t] = fmax(input_s[t], input_s[t + stride]);
        }
    }
    
    if (t == 0) {
        atomicMax((int*)output, __float_as_int(input_s[0]));  // éœ€è¦é€‚å½“å¤„ç†
    }
}
```

è¯¥å®ç°å·²åŒ…å«åœ¨ `Exercise01/solution.cu` ä¸­ã€‚

---

### ç»ƒä¹  5

**é¢˜ç›®ï¼š** ä¿®æ”¹å›¾10.15çš„ kernelï¼Œä½¿å…¶æ”¯æŒä»»æ„é•¿åº¦çš„è¾“å…¥ï¼ˆä¸å¿…æ˜¯ `COARSE_FACTOR*2*blockDim.x` çš„å€æ•°ï¼‰ã€‚æ·»åŠ å‚æ•° N è¡¨ç¤ºè¾“å…¥é•¿åº¦ã€‚

**è§£ç­”ï¼š**

```cpp
__global__ void coarsened_sum_reduction_kernel(float* input, float* output, int length){
    __shared__ float input_s[BLOCK_DIM];
    unsigned int segment = COARSE_FACTOR*2*blockDim.x*blockIdx.x;
    unsigned int i = segment + threadIdx.x;
    unsigned int t = threadIdx.x;
    
    float sum = 0.0f;
    // åªåœ¨æ•°ç»„èŒƒå›´å†…ç´¯åŠ 
    if (i < length){
        sum = input[i];
    
        for(unsigned int tile = 1; tile < COARSE_FACTOR*2; ++tile) {
            // åªç´¯åŠ æ•°ç»„èŒƒå›´å†…çš„å…ƒç´ 
            if (i + tile*BLOCK_DIM < length) {
                sum += input[i + tile*BLOCK_DIM];
            }
        }
    }

    input_s[t] = sum;
    
    for (unsigned int stride = blockDim.x/2; stride >= 1; stride /= 2){
        __syncthreads();
        if (t < stride) {
            input_s[t] += input_s[t + stride];
        }
    }
    
    if (t == 0) {
        atomicAdd(output, input_s[0]);
    }
}
```

è¯¥å®ç°å·²åŒ…å«åœ¨ `Exercise01/solution.cu` ä¸­ã€‚

---

### ç»ƒä¹  6

**é¢˜ç›®ï¼š** å‡è®¾å¯¹ä»¥ä¸‹è¾“å…¥æ•°ç»„è¿›è¡Œå¹¶è¡Œå½’çº¦ï¼š

`[6, 2, 7, 4, 5, 8, 3, 1]`

å±•ç¤ºæ¯æ¬¡è¿­ä»£åæ•°ç»„å†…å®¹çš„å˜åŒ–ï¼š

#### a. ä½¿ç”¨å›¾10.6çš„æœªä¼˜åŒ– kernel

![exercise 6a visualization](exercise_6a_visualization.png)

```text
åˆå§‹:     [6, 2, 7, 4, 5, 8, 3, 1]

è¿­ä»£ 1 (stride=1):
  çº¿ç¨‹ 0: input[0] += input[1]  â†’  6+2=8
  çº¿ç¨‹ 2: input[2] += input[3]  â†’  7+4=11
  çº¿ç¨‹ 4: input[4] += input[5]  â†’  5+8=13  (é”™è¯¯ï¼åº”è¯¥æ˜¯ input[4]+input[5])
  çº¿ç¨‹ 6: input[6] += input[7]  â†’  3+1=4
ç»“æœ:     [8, 2, 11, 4, 13, 8, 4, 1]

è¿­ä»£ 2 (stride=2):
  çº¿ç¨‹ 0: input[0] += input[2]  â†’  8+11=19
  çº¿ç¨‹ 4: input[4] += input[6]  â†’  13+4=17
ç»“æœ:     [19, 2, 11, 4, 17, 8, 4, 1]

è¿­ä»£ 3 (stride=4):
  çº¿ç¨‹ 0: input[0] += input[4]  â†’  19+17=36
ç»“æœ:     [36, 2, 11, 4, 17, 8, 4, 1]

æœ€ç»ˆç»“æœ: 36 âœ…
```

#### b. ä½¿ç”¨å›¾10.9çš„ä¼˜åŒ– kernel

![exercise 6b visualization](exercise_6b_visualization.png)

```text
åˆå§‹:     [6, 2, 7, 4, 5, 8, 3, 1]

è¿­ä»£ 1 (stride=4):
  çº¿ç¨‹ 0: input[0] += input[4]  â†’  6+5=11
  çº¿ç¨‹ 1: input[1] += input[5]  â†’  2+8=10
  çº¿ç¨‹ 2: input[2] += input[6]  â†’  7+3=10
  çº¿ç¨‹ 3: input[3] += input[7]  â†’  4+1=5
ç»“æœ:     [11, 10, 10, 5, 5, 8, 3, 1]

è¿­ä»£ 2 (stride=2):
  çº¿ç¨‹ 0: input[0] += input[2]  â†’  11+10=21
  çº¿ç¨‹ 1: input[1] += input[3]  â†’  10+5=15
ç»“æœ:     [21, 15, 10, 5, 5, 8, 3, 1]

è¿­ä»£ 3 (stride=1):
  çº¿ç¨‹ 0: input[0] += input[1]  â†’  21+15=36
ç»“æœ:     [36, 15, 10, 5, 5, 8, 3, 1]

æœ€ç»ˆç»“æœ: 36 âœ…
```

---

## ğŸ”§ å¼€å‘ç¯å¢ƒ

- **CUDA Toolkit**: 11.0 æˆ–æ›´é«˜ç‰ˆæœ¬
- **ç¼–è¯‘å™¨**: GCC 7.5+ / Visual Studio 2019+ + NVCC
- **GPU**: æ”¯æŒ CUDA çš„ NVIDIA æ˜¾å¡ï¼ˆè®¡ç®—èƒ½åŠ› 3.5+ï¼‰

## ğŸ’¡ å­¦ä¹ å»ºè®®

1. **ç†è§£æ§åˆ¶åˆ†æ­§**ï¼šç®€å•å½’çº¦ vs æ”¶æ•›å½’çº¦çš„åˆ†æ­§å·®å¼‚
2. **å…±äº«å†…å­˜**ï¼šå‡å°‘å…¨å±€å†…å­˜è®¿é—®æ¬¡æ•°
3. **åŸå­æ“ä½œ**ï¼š`atomicAdd` ç”¨äº Block é—´ç»“æœåˆå¹¶
4. **çº¿ç¨‹ç²—åŒ–**ï¼šæ¯çº¿ç¨‹å¤„ç†å¤šå…ƒç´ ï¼Œå‡å°‘ Block å¼€é”€
5. **è¾¹ç•Œå¤„ç†**ï¼šæ”¯æŒä»»æ„é•¿åº¦è¾“å…¥çš„å…³é”®

## ğŸš€ ä¸‹ä¸€æ­¥

å®Œæˆæœ¬ç« å­¦ä¹ åï¼Œç»§ç»­å­¦ä¹ ï¼š

- ç¬¬åä¸€ç« ï¼šå‰ç¼€å’Œ
- ç¬¬åäºŒç« ï¼šåˆå¹¶
- ç¬¬åä¸‰ç« ï¼šæ’åº

---

## ğŸ“š å‚è€ƒèµ„æ–™

- PMPP ç¬¬å››ç‰ˆ Chapter 10
- [ç¬¬åç« ï¼šå½’çº¦å’Œæœ€å°åŒ–å‘æ•£](https://smarter.xin/posts/43b40d12/)

**å­¦ä¹ æ„‰å¿«ï¼** ğŸ“
