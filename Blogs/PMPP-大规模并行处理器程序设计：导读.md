---
title: PMPP-大规模并行处理器程序设计：导读
date: 2026-01-24 17:11:42
tags:
  - CUDA
  - GPU编程
  - 并行计算
  - PMPP
  - 全书导读
  - 学习路线
categories: 知识分享
swiper_index: 4
cover: /img/PMPP.jpg
---

## 前言

《Programming Massively Parallel Processors: A Hands-on Approach》（简称 PMPP）是 GPU 并行编程领域的经典教材，由 NVIDIA 首席科学家 David Kirk 和 Wen-mei Hwu 教授编写。第四版于 2022 年出版，涵盖了截至 Ampere 架构的最新技术。

这本书不只是 CUDA API 手册，更是一部**并行计算思维（Parallel Computational Thinking）**的养成指南。从最基础的线程模型到高级的分布式计算，从简单的向量加法到复杂的深度学习优化，循序渐进地构建完整的并行编程知识体系。

本系列博客完整覆盖了全书 22 章内容，每章一篇。这篇导读将帮助你：

- 快速了解全书结构和各章核心内容
- 找到每章博客的链接
- 根据自身背景选择合适的学习路线

> **📦 配套资源**：本系列文章配有完整的 [GitHub 仓库](https://github.com/psmarter/PMPP-Learning)，包含每章的练习题解答、CUDA 代码实现和详细注释。所有代码都经过测试，可以直接运行。

## 全书结构

PMPP 第四版共 22 章，可以分为四大部分：

```
┌─────────────────────────────────────────────────────────────┐
│  第一部分：CUDA 基础（1-6章）                                 │
│  建立 GPU 编程的基础概念和核心技能                             │
├─────────────────────────────────────────────────────────────┤
│  第二部分：并行模式（7-15章）                                  │
│  学习 9 种核心并行算法模式                                     │
├─────────────────────────────────────────────────────────────┤
│  第三部分：实际应用（16-18章）                                 │
│  在真实场景中应用并行技术                                      │
├─────────────────────────────────────────────────────────────┤
│  第四部分：高级主题（19-22章）                                 │
│  计算思维、分布式计算、高级特性                                 │
└─────────────────────────────────────────────────────────────┘
```

---

## 第一部分：CUDA 基础（1-6章）

这是入门必读部分，建立 GPU 编程的完整基础。

### 📖 各章概要

| 章节 | 标题                 | 核心内容                                     | 博客链接                                    |
| ---- | -------------------- | -------------------------------------------- | ------------------------------------------- |
| 1    | 引言                 | CPU vs GPU 设计哲学、CUDA 生态、异构计算模型 | [阅读](https://smarter.xin/posts/10d278b0/) |
| 2    | 异构数据并行计算     | Thread/Block/Grid 概念、向量加法、错误处理   | [阅读](https://smarter.xin/posts/3ee22ce5/) |
| 3    | 多维网格和数据       | 2D/3D 索引计算、图像处理、边界检查           | [阅读](https://smarter.xin/posts/6b7045b6/) |
| 4    | 计算架构和调度       | SM 结构、Warp 调度、资源限制、占用率         | [阅读](https://smarter.xin/posts/bd5d1d6/)  |
| 5    | 内存架构和数据局部性 | 内存层次、共享内存、**Tiling 技术**          | [阅读](https://smarter.xin/posts/3bb3179b/) |
| 6    | 性能方面的考虑       | 合并访问、Bank 冲突、分支发散、资源分配      | [阅读](https://smarter.xin/posts/220818c3/) |

### 🔑 关键知识点

**硬件架构**：

- GPU 由多个流式多处理器（SM，Streaming Multiprocessor）组成
- 每个 SM 有自己的寄存器、共享内存、L1 缓存
- 线程以32个一组（线程束，Warp）在 SM 上执行

**编程模型**：

- 核函数（Kernel）是在 GPU 上执行的并行函数
- 线程组织为块（Block），块组织为网格（Grid）
- 线程通过 `threadIdx`、`blockIdx`、`blockDim` 确定自己的位置

**内存优化**（最重要）：

- 寄存器 → 共享内存 → L2 缓存 → 全局内存，速度差异可达100倍
- **分块（Tiling）**：将数据分块加载到共享内存，块内复用
- **合并访问（Coalesced Access）**：让线程束内的线程访问连续地址

### 💡 学习建议

1. 第一遍快速浏览 1-3 章，理解基本概念
2. 重点学习 4-6 章，这是性能优化的基础
3. **第 5 章的 Tiled 矩阵乘法必须亲手实现**

---

## 第二部分：并行模式（7-15章）

这是本书的核心部分，介绍 9 种可复用的并行算法模式。

### 📖 各章概要

| 章节 | 标题       | 核心模式                           | 博客链接                                    |
| ---- | ---------- | ---------------------------------- | ------------------------------------------- |
| 7    | 卷积       | Tiling + Halo 处理、常量内存       | [阅读](https://smarter.xin/posts/1c778456/) |
| 8    | 模板       | 寄存器 Tiling、分块时间迭代        | [阅读](https://smarter.xin/posts/93c68d7a/) |
| 9    | 并行直方图 | 原子操作、私有化、聚合             | [阅读](https://smarter.xin/posts/d29973f1/) |
| 10   | 归约       | 树形归约、Warp Shuffle、CUB 库     | [阅读](https://smarter.xin/posts/43b40d12/) |
| 11   | 前缀和     | Kogge-Stone、Brent-Kung、分层 Scan | [阅读](https://smarter.xin/posts/a6fc4cf6/) |
| 12   | 归并       | Co-Rank 技术、并行归并路径         | [阅读](https://smarter.xin/posts/31928809/) |
| 13   | 排序       | 基数排序、归并排序、Thrust 库      | [阅读](https://smarter.xin/posts/d9ee9484/) |
| 14   | 稀疏矩阵   | CSR/ELL/COO/HYB 格式、SpMV         | [阅读](https://smarter.xin/posts/7af84cf7/) |
| 15   | 图遍历     | 并行 BFS、边界推进、层级同步       | [阅读](https://smarter.xin/posts/70b05668/) |

### 🔑 关键知识点

**数据并行模式**：

| 模式           | 特点       | 典型应用           |
| -------------- | ---------- | ------------------ |
| Map            | 一对一变换 | 向量运算、图像滤波 |
| Reduce         | 多对一归约 | 求和、最大值       |
| Scan           | 前缀操作   | 压缩、流分配       |
| Gather/Scatter | 不规则访问 | 稀疏矩阵、图计算   |

**输出冲突处理**（第 9 章）：

- 原子操作：正确但慢
- 私有化：每线程/每 Block 私有副本
- 聚合：相同地址只做一次原子操作

**树形并行**（第 10-11 章）：

- 归约：多个值 → 一个值
- 扫描：多个值 → 多个前缀和
- 都是 O(log N) 步，但 Scan 更复杂

### 💡 学习建议

1. 第 7 章卷积是第 5 章 Tiling 的进阶应用
2. **第 10-11 章（归约和前缀和）是最重要的两章**
3. 稀疏矩阵和图遍历展示了如何处理不规则数据

---

## 第三部分：实际应用（16-18章）

将前面学到的技术应用于真实的科学计算和工程问题。

### 📖 各章概要

| 章节 | 标题            | 应用领域                           | 博客链接                                    |
| ---- | --------------- | ---------------------------------- | ------------------------------------------- |
| 16   | 深度学习        | 卷积神经网络、Im2col、Tensor Core  | [阅读](https://smarter.xin/posts/feaca34d/) |
| 17   | 迭代式 MRI 重建 | NUFFT、共轭梯度、医学成像          | [阅读](https://smarter.xin/posts/fab0715b/) |
| 18   | 静电势能图      | N-body 问题、空间分区、cutoff 优化 | [阅读](https://smarter.xin/posts/d7c6e6a8/) |

### 🔑 关键知识点

**深度学习（第 16 章）**：

- 卷积是 95%+ 的计算量
- Im2col 把卷积转为 GEMM
- Winograd 减少乘法次数
- cuDNN 自动选择最优算法

**科学计算**：

- 迭代算法需要多次 Kernel 启动
- 非均匀网格需要特殊处理
- 空间分区降低 O(N²) 到 O(N)

### 💡 学习建议

1. 如果做深度学习，第 16 章必读
2. 第 17-18 章展示科学计算的完整流程
3. 理解如何组合多种技术解决复杂问题

---

## 第四部分：高级主题（19-22章）

计算思维方法论、分布式扩展和未来趋势。

### 📖 各章概要

| 章节 | 标题               | 核心内容                           | 博客链接                                    |
| ---- | ------------------ | ---------------------------------- | ------------------------------------------- |
| 19   | 并行编程与计算思维 | 问题分解、算法选择、性能推理       | [阅读](https://smarter.xin/posts/46b3d994/) |
| 20   | 异构计算集群编程   | MPI+CUDA、多 GPU、Halo 交换        | [阅读](https://smarter.xin/posts/9506dbb9/) |
| 21   | CUDA 动态并行性    | 设备端启动、递归算法、自适应网格   | [阅读](https://smarter.xin/posts/e519c4bc/) |
| 22   | 高级实践与未来演变 | 性能方法论、代码可移植性、发展趋势 | [阅读](https://smarter.xin/posts/a3a140de/) |

### 🔑 关键知识点

**计算思维（第 19 章）**：

- 识别并行性：数据并行 vs 任务并行
- 算法选择：计算复杂度 vs 并行度
- 性能推理：Roofline 模型

**分布式扩展（第 20 章）**：

- 多 GPU：CUDA-aware MPI、GPUDirect
- 通信隐藏：重叠计算和传输
- 弱扩展 vs 强扩展

**动态并行（第 21 章）**：

- 设备端可以启动子 Kernel
- 适合递归和自适应算法
- 有同步和开销限制

### 💡 学习建议

1. 第 19 章提炼了全书的方法论精华
2. 如果需要多 GPU/多节点，重点学第 20 章
3. 第 22 章可作为持续学习的指南

---

## 核心知识图谱

### 内存优化技术

```
                    ┌──────────────────────────────────────┐
                    │         GPU 内存层次结构              │
                    ├──────────────────────────────────────┤
                    │  寄存器 (~TB/s) ◀── 最快，数量有限    │
                    │     ↓                                │
                    │  共享内存 (~10 TB/s) ◀── 可编程缓存   │
                    │     ↓                                │
                    │  L2 缓存 (~1 TB/s) ◀── 自动管理       │
                    │     ↓                                │
                    │  全局内存 (~500 GB/s) ◀── 容量大但慢  │
                    └──────────────────────────────────────┘

优化策略：
├── Tiling（第5章）：数据分块，在共享内存中复用
├── 合并访问（第6章）：连续地址，减少内存事务
├── 寄存器Tiling（第8章）：数据保留在寄存器
└── 私有化（第9章）：避免原子操作的竞争
```

### 并行算法选择

```
问题类型                    推荐算法
───────────────────────────────────────────────
逐元素运算                  Map（直接并行）
全局聚合（求和/最大值）      树形归约（第10章）
前缀依赖计算                Scan（第11章）
有序数据合并                Co-rank归并（第12章）
整数键排序                  基数排序（第13章）
稀疏数据处理                CSR/ELL格式（第14章）
图遍历                      边界推进BFS（第15章）
```

### 性能调优方法论

```
1. Profile 先行
   └── 使用 Nsight Compute 定位瓶颈

2. 判断瓶颈类型
   ├── 内存受限：优化访问模式、增加数据复用
   └── 计算受限：减少指令数、使用快速数学函数

3. 层次化优化（从上到下收益递减）
   ├── 算法选择
   ├── 数据布局
   ├── 并行策略
   ├── 内存层次利用
   └── 指令级优化

4. 迭代验证
   └── 保持正确性，逐步优化
```

---

## 学习路线推荐

### 🚀 快速入门路线（2周）

适合：有编程基础，想快速上手 CUDA

```
Week 1: 1→2→3→5（基础概念 + Tiling）
Week 2: 10→16（归约 + 深度学习应用）
```

### 📚 系统学习路线（2月）

适合：想深入掌握 GPU 编程

```
Month 1（基础+模式）:
  Week 1-2: 1-6章（打牢基础）
  Week 3-4: 7-11章（核心模式）

Month 2（进阶+应用）:
  Week 1-2: 12-16章（高级模式+应用）
  Week 3-4: 19-22章（思维+扩展）
```

### 🎯 专项提升路线

**深度学习方向**：1→2→5→7→10→16

**科学计算方向**：1→2→5→10→11→14→17→18

**HPC 方向**：1→2→4→5→6→10→20

---

## 学习资源

### 配套代码

- **GitHub 仓库**：[https://github.com/psmarter/PMPP-Learning](https://github.com/psmarter/PMPP-Learning)
- 包含所有章节练习题解答
- 可直接编译运行的 CUDA 代码
- 详细的中文注释

### 官方资源

- [CUDA C++ Programming Guide](https://docs.nvidia.com/cuda/cuda-c-programming-guide/)
- [CUDA Best Practices Guide](https://docs.nvidia.com/cuda/cuda-c-best-practices-guide/)
- [Nsight Compute Documentation](https://docs.nvidia.com/nsight-compute/)

### 相关课程

- UIUC ECE 408（Coursera 可看）
- 书籍作者的配套课程

---

## 写在最后

PMPP 不是一本可以一次读完的书。第一遍建立框架，第二遍深入细节，每次实战后再回来都会有新的理解。

**学习建议**：

1. **动手实践**：每章的练习题都需要实际编码，仅阅读难以真正掌握
2. **使用性能分析工具**：Nsight Compute 和 Nsight Systems 是理解性能的最佳途径
3. **理解底层原理**：API 会更新，但硬件原理和优化思想具有长期价值
4. **项目驱动**：在真实项目中应用这些技术才能融会贯通

GPU 并行编程的重要性日益凸显——深度学习、科学计算、图形渲染、高性能计算都离不开它。掌握 PMPP 的内容，就掌握了进入这些领域的核心技能。

祝学习进步！

---

**参考资料：**

- Hwu, W., Kirk, D., & El Hajj, I. (2022). *Programming Massively Parallel Processors: A Hands-on Approach* (4th Edition). Morgan Kaufmann.
- [NVIDIA CUDA 官方文档](https://docs.nvidia.com/cuda/)
- [NVIDIA Developer Blog](https://developer.nvidia.com/blog/)

---

> **本文 GitHub 仓库**: [https://github.com/psmarter/PMPP-Learning](https://github.com/psmarter/PMPP-Learning)
>
> **系列总览**：本文是 PMPP 全书 22 章博客系列的导读索引。
