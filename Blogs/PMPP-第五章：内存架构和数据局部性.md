---
title: PMPP-ç¬¬äº”ç« ï¼šå†…å­˜æ¶æ„å’Œæ•°æ®å±€éƒ¨æ€§
date: 2026-01-16 10:16:08
tags:
  - CUDA
  - GPUç¼–ç¨‹
  - å¹¶è¡Œè®¡ç®—
  - PMPP
  - å…±äº«å†…å­˜
  - Tiling
categories: çŸ¥è¯†åˆ†äº«
cover: /img/PMPP.jpg
---

## å‰è¨€

ç¬¬å››ç« ç†è§£äº†GPUçš„è°ƒåº¦æœºåˆ¶å’Œç¡¬ä»¶æ¶æ„ï¼Œè¿™ä¸€ç« è¿›å…¥æ€§èƒ½ä¼˜åŒ–çš„æ ¸å¿ƒâ€”â€”å†…å­˜ã€‚GPUè®¡ç®—èƒ½åŠ›å¼ºå¤§ï¼Œä½†æ•°æ®ä¾›åº”è·Ÿä¸ä¸Šå°±ç™½æ­ã€‚ç¬¬äº”ç« è®²è§£GPUçš„å†…å­˜å±‚æ¬¡ç»“æ„ï¼Œé‡ç‚¹æ˜¯Shared Memoryå’ŒTilingæŠ€æœ¯ã€‚æŒæ¡è¿™äº›ï¼ŒçŸ©é˜µä¹˜æ³•æ€§èƒ½å¯ä»¥æå‡10å€ä»¥ä¸Šã€‚

> **ğŸ“¦ é…å¥—èµ„æº**ï¼šæœ¬ç³»åˆ—æ–‡ç« é…æœ‰å®Œæ•´çš„ [GitHub ä»“åº“](https://github.com/psmarter/PMPP-Learning)ï¼ŒåŒ…å«æ¯ç« çš„ç»ƒä¹ é¢˜è§£ç­”ã€CUDA ä»£ç å®ç°å’Œè¯¦ç»†æ³¨é‡Šã€‚æ‰€æœ‰ä»£ç éƒ½ç»è¿‡æµ‹è¯•ï¼Œå¯ä»¥ç›´æ¥è¿è¡Œã€‚

## å†…å­˜å¸¦å®½ï¼šæ€§èƒ½çš„å¤©èŠ±æ¿

### é—®é¢˜çš„æœ¬è´¨

å›é¡¾ç¬¬ä¸‰ç« çš„çŸ©é˜µä¹˜æ³•ï¼š

```cuda
__global__ void matMul(float *M, float *N, float *P, int width) {
    int row = blockIdx.y * blockDim.y + threadIdx.y;
    int col = blockIdx.x * blockDim.x + threadIdx.x;
    
    if (row < width && col < width) {
        float sum = 0.0f;
        for (int k = 0; k < width; k++) {
            sum += M[row * width + k] * N[k * width + col];
        }
        P[row * width + col] = sum;
    }
}
```

è®¡ç®— P[row][col] éœ€è¦è¯»å– M çš„ä¸€è¡Œå’Œ N çš„ä¸€åˆ—ï¼Œå…± 2Ã—width ä¸ªå…ƒç´ ã€‚æ¯ä¸ªå…ƒç´  4 å­—èŠ‚ï¼Œwidth=1024 æ—¶ï¼š

```
æ¯çº¿ç¨‹è¯»å–ï¼š2 Ã— 1024 Ã— 4 = 8192 å­—èŠ‚
æ¯çº¿ç¨‹è®¡ç®—ï¼š2 Ã— 1024 = 2048 FLOP
ç®—æœ¯å¼ºåº¦ï¼š2048 / 8192 = 0.25 FLOP/Byte
```

ç°ä»£ GPU å³°å€¼ 10+ TFLOPSï¼Œå¸¦å®½ 500+ GB/sï¼Œéœ€è¦ 20 FLOP/Byte æ‰èƒ½è·‘æ»¡è®¡ç®—å•å…ƒã€‚å®é™…åªæœ‰ 0.25ï¼Œ**GPU å¤§éƒ¨åˆ†æ—¶é—´åœ¨ç­‰æ•°æ®**ã€‚

### æ•°æ®é‡å¤è®¿é—®

æ›´ä¸¥é‡çš„æ˜¯ï¼š**åŒä¸€æ•°æ®è¢«å¤šä¸ªçº¿ç¨‹é‡å¤è¯»å–**ã€‚

M[i][k] è¢«ç¬¬ i è¡Œçš„æ‰€æœ‰çº¿ç¨‹è¯»å–ï¼ŒN[k][j] è¢«ç¬¬ j åˆ—çš„æ‰€æœ‰çº¿ç¨‹è¯»å–ã€‚1024Ã—1024 çŸ©é˜µï¼Œæ¯ä¸ªå…ƒç´ è¢«è¯» 1024 æ¬¡ï¼Œä½†æ¯æ¬¡éƒ½ä»å…¨å±€å†…å­˜ï¼ˆDRAMï¼‰è¯»ã€‚

è¿™å°±æ˜¯ä¼˜åŒ–çš„åˆ‡å…¥ç‚¹ï¼š**è®©æ•°æ®å¤ç”¨å‘ç”Ÿåœ¨å¿«é€Ÿå­˜å‚¨ä¸Šï¼Œè€Œä¸æ˜¯å…¨å±€å†…å­˜**ã€‚

## GPU å†…å­˜å±‚æ¬¡

### å±‚æ¬¡ç»“æ„

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                   Host Memory               â”‚   CPU DDR4/DDR5
â”‚                   (GB çº§åˆ«)                  â”‚   ~50 GB/s
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚              Global Memory (DRAM)           â”‚   GPU æ˜¾å­˜
â”‚                  (GB çº§åˆ«)                   â”‚   ~500 GB/s
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚    L2 Cache (SM å…±äº«)                        â”‚   å‡  MB
â”‚                                              â”‚   ~1-2 TB/s
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚   Shared     â”‚   Shared     â”‚   Shared      â”‚   æ¯ SM
â”‚   Memory     â”‚   Memory     â”‚   Memory      â”‚   ~100 KB
â”‚   L1 Cache   â”‚   L1 Cache   â”‚   L1 Cache    â”‚   ~10 TB/s
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚  Registers   â”‚  Registers   â”‚  Registers    â”‚   æ¯çº¿ç¨‹
â”‚              â”‚              â”‚               â”‚   ~å‡ å TB/s
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
     SM 0           SM 1           SM 2
```

**æ ¸å¿ƒè§„å¾‹**ï¼šè¶Šé è¿‘è®¡ç®—å•å…ƒï¼Œå®¹é‡è¶Šå°ï¼Œé€Ÿåº¦è¶Šå¿«ã€‚

### å„çº§å­˜å‚¨ç‰¹ç‚¹

| å­˜å‚¨ç±»å‹ | ä½œç”¨åŸŸ  | å®¹é‡        | å»¶è¿Ÿ     | ç¨‹åºå‘˜æ§åˆ¶   |
| -------- | ------- | ----------- | -------- | ------------ |
| å¯„å­˜å™¨   | å•çº¿ç¨‹  | ~255ä¸ª/çº¿ç¨‹ | 1å‘¨æœŸ    | éšå¼ï¼ˆå˜é‡ï¼‰ |
| å…±äº«å†…å­˜ | Blockå†… | ~100KB/SM   | ~20å‘¨æœŸ  | æ˜¾å¼         |
| L1ç¼“å­˜   | SMå†…    | ~128KB/SM   | ~20å‘¨æœŸ  | éƒ¨åˆ†         |
| L2ç¼“å­˜   | å…¨å±€    | ~6MB        | ~200å‘¨æœŸ | æ—            |
| å…¨å±€å†…å­˜ | å…¨å±€    | ~æ•°GB       | ~400å‘¨æœŸ | æ˜¾å¼         |

**å…³é”®æ´å¯Ÿ**ï¼š

- **å¯„å­˜å™¨**æœ€å¿«ï¼Œä½†å®¹é‡æœ‰é™ï¼Œä¸”åªå±äºå•ä¸ªçº¿ç¨‹
- **å…±äº«å†…å­˜**æ˜¯ç¨‹åºå‘˜å¯æ§çš„ Block çº§ç¼“å­˜ï¼Œè¿™æ˜¯ä¼˜åŒ–çš„ä¸»æˆ˜åœº
- **å…¨å±€å†…å­˜**æ˜¯å”¯ä¸€èƒ½å®¹çº³å¤§æ•°æ®çš„åœ°æ–¹ï¼Œä½†å¤ªæ…¢

## å…±äº«å†…å­˜ï¼ˆShared Memoryï¼‰

### åŸºæœ¬æ¦‚å¿µ

å…±äº«å†…å­˜æ˜¯ SM ä¸Šçš„å¯ç¼–ç¨‹ç¼“å­˜ï¼š

- **Block å†…æ‰€æœ‰çº¿ç¨‹å…±äº«**ï¼šåŒ Block çš„çº¿ç¨‹å¯ä»¥è¯»å†™åŒä¸€å—å…±äº«å†…å­˜
- **ç”Ÿå‘½å‘¨æœŸä¸ Block ç»‘å®š**ï¼šBlock ç»“æŸï¼Œå…±äº«å†…å­˜é‡Šæ”¾
- **ä½å»¶è¿Ÿ**ï¼šçº¦ 20 å‘¨æœŸï¼Œæ¯”å…¨å±€å†…å­˜å¿« 20 å€

### å£°æ˜è¯­æ³•

**é™æ€åˆ†é…**ï¼ˆç¼–è¯‘æ—¶ç¡®å®šå¤§å°ï¼‰ï¼š

```cuda
__global__ void kernel() {
    __shared__ float sharedData[256];  // Block å†…å…±äº«
    // ...
}
```

**åŠ¨æ€åˆ†é…**ï¼ˆè¿è¡Œæ—¶ç¡®å®šå¤§å°ï¼‰ï¼š

```cuda
__global__ void kernel() {
    extern __shared__ float sharedData[];  // å¤§å°ç”±å¯åŠ¨é…ç½®æŒ‡å®š
    // ...
}

// å¯åŠ¨æ—¶æŒ‡å®šå…±äº«å†…å­˜å¤§å°
kernel<<<grid, block, sharedMemBytes>>>(args);
```

### åŒæ­¥ï¼š__syncthreads()

å…±äº«å†…å­˜æ˜¯ Block å†…å…±äº«çš„ï¼Œéœ€è¦åŒæ­¥ä¿è¯æ•°æ®ä¸€è‡´æ€§ï¼š

```cuda
__shared__ float data[256];

// é˜¶æ®µ1ï¼šæ‰€æœ‰çº¿ç¨‹å†™å…¥
data[threadIdx.x] = input[globalIdx];

__syncthreads();  // ç­‰å¾…æ‰€æœ‰çº¿ç¨‹å®Œæˆå†™å…¥

// é˜¶æ®µ2ï¼šæ‰€æœ‰çº¿ç¨‹è¯»å–ï¼ˆæ­¤æ—¶æ•°æ®å·²å°±ç»ªï¼‰
float val = data[(threadIdx.x + 1) % 256];
```

**__syncthreads() æ˜¯æ …æ åŒæ­¥**ï¼šBlock å†…æ‰€æœ‰çº¿ç¨‹å¿…é¡»åˆ°è¾¾è¿™ä¸€ç‚¹ï¼Œæ‰èƒ½ç»§ç»­æ‰§è¡Œã€‚

**å¸¸è§é”™è¯¯**ï¼š

```cuda
// å±é™©ï¼æ¡ä»¶å†…ä½¿ç”¨ syncthreads
if (threadIdx.x < 128) {
    data[threadIdx.x] = ...;
    __syncthreads();  // åªæœ‰éƒ¨åˆ†çº¿ç¨‹æ‰§è¡Œï¼Œä¼šæ­»é”ï¼
}
```

åŒæ­¥å¿…é¡»ä¿è¯ Block å†…æ‰€æœ‰æ´»è·ƒçº¿ç¨‹éƒ½æ‰§è¡Œåˆ°ã€‚

## Tilingï¼šåˆ†å—å¤„ç†

### æ ¸å¿ƒæ€æƒ³

æ—¢ç„¶å…¨å±€å†…å­˜æ…¢ä½†å…±äº«å†…å­˜å¿«ï¼Œç­–ç•¥å°±æ˜¯ï¼š

1. **åˆ†å—åŠ è½½**ï¼šå°†æ•°æ®åˆ†æˆå°å—ï¼ˆTileï¼‰ï¼Œé€å—åŠ è½½åˆ°å…±äº«å†…å­˜
2. **è®¡ç®—å¤ç”¨**ï¼šåœ¨å…±äº«å†…å­˜ä¸­å®Œæˆè¯¥å—çš„æ‰€æœ‰è®¡ç®—
3. **ç§»åŠ¨çª—å£**ï¼šå¤„ç†ä¸‹ä¸€å—ï¼Œç›´åˆ°å®Œæˆ

è¿™æ ·ï¼Œæ¯ä¸ªæ•°æ®ä»å…¨å±€å†…å­˜åªè¯»ä¸€æ¬¡ï¼Œä½†åœ¨å…±äº«å†…å­˜ä¸­è¢«å¤šæ¬¡ä½¿ç”¨ã€‚

### Tiled çŸ©é˜µä¹˜æ³•

**é—®é¢˜**ï¼šè®¡ç®— P = M Ã— Nï¼Œæ¯ä¸ª P[i][j] = Î£ M[i][k] Ã— N[k][j]

**æœ´ç´ ç‰ˆæœ¬**ï¼šæ¯ä¸ªçº¿ç¨‹ç‹¬ç«‹è¯»å–æ•´è¡Œå’Œæ•´åˆ—ï¼ˆå¤§é‡é‡å¤è¯»å–ï¼‰

**Tiled ç‰ˆæœ¬**ï¼š

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”   â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚   M çŸ©é˜µ       â”‚   â”‚   N çŸ©é˜µ       â”‚
â”‚  â”Œâ”€â”€â”€â”        â”‚   â”‚      â”Œâ”€â”€â”€â”    â”‚
â”‚  â”‚Tileâ”‚ â”€â”€â”€â”€â†’ â”‚   â”‚      â”‚Tileâ”‚   â”‚
â”‚  â””â”€â”€â”€â”˜        â”‚   â”‚      â””â”€â”€â”€â”˜    â”‚
â”‚               â”‚   â”‚        â”‚      â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜   â””â”€â”€â”€â”€â”€â”€â”€â”€â”‚â”€â”€â”€â”€â”€â”€â”˜
                             â†“
                    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
                    â”‚   P çŸ©é˜µ       â”‚
                    â”‚      â”Œâ”€â”€â”€â”    â”‚
                    â”‚      â”‚è®¡ç®—â”‚    â”‚
                    â”‚      â””â”€â”€â”€â”˜    â”‚
                    â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

**æ­¥éª¤**ï¼š

1. å°† M çš„ä¸€ä¸ª Tile å’Œ N çš„ä¸€ä¸ª Tile åŠ è½½åˆ°å…±äº«å†…å­˜
2. Block å†…æ‰€æœ‰çº¿ç¨‹ä½¿ç”¨å…±äº«å†…å­˜ä¸­çš„æ•°æ®è¿›è¡Œéƒ¨åˆ†è®¡ç®—
3. åŠ è½½ä¸‹ä¸€å¯¹ Tileï¼Œç´¯åŠ ç»“æœ
4. é‡å¤ç›´åˆ°å®Œæˆ

### ä»£ç å®ç°

```cuda
#define TILE_WIDTH 16

__global__ void matMulTiled(float *M, float *N, float *P, int width) {
    // å…±äº«å†…å­˜å£°æ˜
    __shared__ float Mds[TILE_WIDTH][TILE_WIDTH];
    __shared__ float Nds[TILE_WIDTH][TILE_WIDTH];
    
    int bx = blockIdx.x, by = blockIdx.y;
    int tx = threadIdx.x, ty = threadIdx.y;
    
    // è®¡ç®—è¯¥çº¿ç¨‹è´Ÿè´£çš„ P å…ƒç´ ä½ç½®
    int row = by * TILE_WIDTH + ty;
    int col = bx * TILE_WIDTH + tx;
    
    float Pvalue = 0;
    
    // åˆ†å—å¾ªç¯
    for (int ph = 0; ph < width / TILE_WIDTH; ++ph) {
        
        // åä½œåŠ è½½ M çš„ Tile
        Mds[ty][tx] = M[row * width + (ph * TILE_WIDTH + tx)];
        
        // åä½œåŠ è½½ N çš„ Tile
        Nds[ty][tx] = N[(ph * TILE_WIDTH + ty) * width + col];
        
        __syncthreads();  // ç¡®ä¿ Tile åŠ è½½å®Œæˆ
        
        // ä½¿ç”¨å…±äº«å†…å­˜è®¡ç®—éƒ¨åˆ†ç‚¹ç§¯
        for (int k = 0; k < TILE_WIDTH; ++k) {
            Pvalue += Mds[ty][k] * Nds[k][tx];
        }
        
        __syncthreads();  // ç¡®ä¿è®¡ç®—å®Œæˆå†åŠ è½½ä¸‹ä¸€ä¸ª Tile
    }
    
    P[row * width + col] = Pvalue;
}
```

### å…³é”®ç‚¹è§£æ

**1. åä½œåŠ è½½**

Block å†…çš„çº¿ç¨‹åˆ†å·¥åŠ è½½ Tileï¼š

```cuda
Mds[ty][tx] = M[row * width + (ph * TILE_WIDTH + tx)];
```

æ¯ä¸ªçº¿ç¨‹åŠ è½½ä¸€ä¸ªå…ƒç´ ï¼Œ16Ã—16 = 256 ä¸ªçº¿ç¨‹åŠ è½½ 256 ä¸ªå…ƒç´ ã€‚æ¯”å•çº¿ç¨‹åŠ è½½æ•´ä¸ª Tile é«˜æ•ˆå¾—å¤šã€‚

**2. ä¸¤æ¬¡åŒæ­¥**

```cuda
__syncthreads();  // ç¬¬ä¸€æ¬¡ï¼šç¡®ä¿æ•°æ®åŠ è½½å®Œæˆ
// ... è®¡ç®— ...
__syncthreads();  // ç¬¬äºŒæ¬¡ï¼šç¡®ä¿è®¡ç®—å®Œæˆå†è¦†ç›–å…±äº«å†…å­˜
```

ä¸¤æ¬¡åŒæ­¥éƒ½å¿…è¦ï¼š

- ç¬¬ä¸€æ¬¡ï¼šé˜²æ­¢è¯»åˆ°æœªåŠ è½½çš„æ•°æ®
- ç¬¬äºŒæ¬¡ï¼šé˜²æ­¢å¿«çº¿ç¨‹è¦†ç›–æ…¢çº¿ç¨‹è¿˜åœ¨ç”¨çš„æ•°æ®

**3. å†…å±‚å¾ªç¯**

```cuda
for (int k = 0; k < TILE_WIDTH; ++k) {
    Pvalue += Mds[ty][k] * Nds[k][tx];
}
```

è¿™ä¸ªå¾ªç¯åªè®¿é—®å…±äº«å†…å­˜ï¼Œæ²¡æœ‰å…¨å±€å†…å­˜è®¿é—®ã€‚è¿™æ˜¯æ€§èƒ½æå‡çš„æ¥æºã€‚

### æ€§èƒ½åˆ†æ

**æœ´ç´ ç‰ˆæœ¬**ï¼š

- æ¯çº¿ç¨‹è¯»å–å…¨å±€å†…å­˜ï¼š2 Ã— width æ¬¡
- æ€»å…¨å±€å†…å­˜è®¿é—®ï¼šwidthÂ³ Ã— 2ï¼ˆè¯»ï¼‰+ widthÂ²ï¼ˆå†™ï¼‰

**Tiled ç‰ˆæœ¬**ï¼š

- æ¯ Tile é˜¶æ®µï¼šBlock è¯» 2 Ã— TILE_WIDTHÂ² ä¸ªå…ƒç´ 
- å…± width/TILE_WIDTH ä¸ªé˜¶æ®µ
- æ¯çº¿ç¨‹è´¡çŒ®ï¼š2 Ã— width æ¬¡ï¼ˆä¸æœ´ç´ ç›¸åŒï¼Ÿä¸å¯¹ï¼ï¼‰

**å…³é”®å·®å¼‚**ï¼šåœ¨ Tiled ç‰ˆæœ¬ä¸­ï¼Œæ¯ä¸ªå…¨å±€å†…å­˜è¯»å–è¢« TILE_WIDTH ä¸ªçº¿ç¨‹å…±äº«ä½¿ç”¨ã€‚

```
å…¨å±€å†…å­˜è®¿é—®å‡å°‘å€æ•° = TILE_WIDTH
ç®—æœ¯å¼ºåº¦æå‡ = TILE_WIDTH å€
```

TILE_WIDTH = 16 æ—¶ï¼Œç®—æœ¯å¼ºåº¦ä» 0.25 æå‡åˆ° 4 FLOP/Byteã€‚TILE_WIDTH = 32 æ—¶å¯è¾¾ 8 FLOP/Byteã€‚

### è¾¹ç•Œå¤„ç†

ä¸Šé¢çš„ä»£ç å‡è®¾ width æ˜¯ TILE_WIDTH çš„å€æ•°ã€‚å®é™…éœ€è¦å¤„ç†è¾¹ç•Œï¼š

```cuda
// å¸¦è¾¹ç•Œæ£€æŸ¥çš„åŠ è½½
if (row < width && (ph * TILE_WIDTH + tx) < width)
    Mds[ty][tx] = M[row * width + (ph * TILE_WIDTH + tx)];
else
    Mds[ty][tx] = 0;  // è¶Šç•Œå…ƒç´ å¡«0

if ((ph * TILE_WIDTH + ty) < width && col < width)
    Nds[ty][tx] = N[(ph * TILE_WIDTH + ty) * width + col];
else
    Nds[ty][tx] = 0;
```

å¡« 0 ä¸å½±å“åŠ æ³•ç»“æœï¼Œæ˜¯å¤„ç†è¾¹ç•Œçš„å¸¸ç”¨æŠ€å·§ã€‚

## å†…å­˜è®¿é—®æ¨¡å¼

### åˆå¹¶è®¿é—®ï¼ˆCoalesced Accessï¼‰

GPU å†…å­˜æ§åˆ¶å™¨æŒ‰ **32 å­—èŠ‚æˆ– 128 å­—èŠ‚** çš„äº‹åŠ¡è¯»å†™æ•°æ®ã€‚å¦‚æœ Warp ä¸­çš„çº¿ç¨‹è®¿é—®è¿ç»­åœ°å€ï¼Œå¯ä»¥åˆå¹¶æˆä¸€æ¬¡äº‹åŠ¡ï¼š

**å¥½çš„è®¿é—®æ¨¡å¼**ï¼š

```cuda
// çº¿ç¨‹ 0,1,2,...,31 è®¿é—®è¿ç»­åœ°å€
data[threadIdx.x];  // ä¸€æ¬¡ 128B äº‹åŠ¡
```

**å·®çš„è®¿é—®æ¨¡å¼**ï¼š

```cuda
// çº¿ç¨‹ 0,1,2,...,31 è®¿é—®è·¨æ­¥åœ°å€
data[threadIdx.x * 32];  // 32 æ¬¡äº‹åŠ¡ï¼
```

**çŸ©é˜µè®¿é—®çš„é™·é˜±**ï¼š

```cuda
// P[i][j] éå†
// æŒ‰è¡Œéå†ï¼ˆå¥½ï¼‰ï¼šdata[row * width + col]ï¼Œcol è¿ç»­
// æŒ‰åˆ—éå†ï¼ˆå·®ï¼‰ï¼šdata[row * width + col]ï¼Œrow è¿ç»­ï¼ˆè·¨æ­¥ = widthï¼‰
```

### å…±äº«å†…å­˜ Bank å†²çª

å…±äº«å†…å­˜åˆ†æˆ 32 ä¸ª **Bank**ï¼Œæ¯ä¸ª Bank å®½åº¦ 4 å­—èŠ‚ã€‚ä¸åŒ Bank å¯ä»¥åŒæ—¶è®¿é—®ï¼Œä½†åŒä¸€ Bank çš„ä¸åŒåœ°å€ä¼šä¸²è¡ŒåŒ–ã€‚

**Bank æ˜ å°„**ï¼š

```
åœ°å€ 0,32,64,...  â†’ Bank 0
åœ°å€ 4,36,68,...  â†’ Bank 1
åœ°å€ 8,40,72,...  â†’ Bank 2
...
åœ°å€ 124,156,... â†’ Bank 31
```

**æ— å†²çª**ï¼š

```cuda
data[threadIdx.x];      // 32 çº¿ç¨‹è®¿é—® 32 ä¸ª Bank
data[threadIdx.x * 2];  // è·¨æ­¥ 2ï¼Œè®¿é—® Bank 0,2,4,...ï¼ˆæ— å†²çªï¼‰
```

**æœ‰å†²çª**ï¼š

```cuda
data[threadIdx.x * 32]; // æ‰€æœ‰çº¿ç¨‹è®¿é—® Bank 0ï¼32-way å†²çª
```

**ç‰¹ä¾‹â€”â€”å¹¿æ’­**ï¼š

```cuda
data[0];  // æ‰€æœ‰çº¿ç¨‹è¯»åŒä¸€åœ°å€ï¼Œç¡¬ä»¶å¹¿æ’­ï¼Œæ— å†²çª
```

### çŸ©é˜µè½¬ç½®çš„ Bank å†²çª

è€ƒè™‘å…±äº«å†…å­˜ä¸­ 16Ã—16 çš„çŸ©é˜µï¼š

```cuda
__shared__ float tile[16][16];

// åŠ è½½ï¼ˆåˆ—è®¿é—®ï¼‰
tile[ty][tx] = input[row * width + col];  // æ— å†²çª

// å­˜å‚¨ï¼ˆè¡Œè®¿é—®ï¼‰
output[col * width + row] = tile[tx][ty];  // æœ‰å†²çªï¼
```

`tile[tx][ty]` ä½¿å¾—çº¿ç¨‹ 0,1,2,...,15 åˆ†åˆ«è®¿é—® tile[0][ty], tile[1][ty], ...ï¼Œè¿™äº›å…ƒç´ åœ°å€ä¸º ty, ty+16, ty+32, ...ï¼Œæ­¥é•¿ 16Ã—4 = 64 å­—èŠ‚ = 16 ä¸ª Bankã€‚éƒ¨åˆ†çº¿ç¨‹ä¼šè®¿é—®åŒä¸€ Bankã€‚

**è§£å†³æ–¹æ¡ˆâ€”â€”Padding**ï¼š

```cuda
__shared__ float tile[16][17];  // å¤šåŠ ä¸€åˆ—

// ç°åœ¨ tile[i][j] çš„åœ°å€æ˜¯ i*17 + j
// æ­¥é•¿å˜æˆ 17Ã—4 = 68 å­—èŠ‚ï¼Œä¸å†å¯¹é½
```

Padding æ‰“ç ´äº† Bank å¯¹é½ï¼Œæ¶ˆé™¤å†²çªã€‚ä»£ä»·æ˜¯æµªè´¹ä¸€ç‚¹å…±äº«å†…å­˜ã€‚

## å¸¸é‡å†…å­˜ï¼ˆConstant Memoryï¼‰

### ç‰¹ç‚¹

- **åªè¯»**ï¼šKernel å†…ä¸èƒ½å†™
- **ç¼“å­˜ä¼˜åŒ–**ï¼šæœ‰ä¸“ç”¨ç¼“å­˜ï¼Œå¹¿æ’­è®¿é—®æ•ˆç‡é«˜
- **å®¹é‡æœ‰é™**ï¼š64 KB

### é€‚ç”¨åœºæ™¯

æ‰€æœ‰çº¿ç¨‹è¯»ç›¸åŒæ•°æ®ï¼ˆå¦‚å·ç§¯æ ¸ã€å˜æ¢çŸ©é˜µï¼‰ï¼š

```cuda
__constant__ float kernel[9];  // å£°æ˜

// Host ç«¯å†™å…¥
cudaMemcpyToSymbol(kernel, h_kernel, 9 * sizeof(float));

// Kernel å†…ä½¿ç”¨
__global__ void conv(...) {
    float sum = 0;
    for (int i = 0; i < 9; i++) {
        sum += data[i] * kernel[i];  // æ‰€æœ‰çº¿ç¨‹è¯»ç›¸åŒ kernel[i]
    }
}
```

å¦‚æœæ¯ä¸ªçº¿ç¨‹è¯»ä¸åŒåœ°å€ï¼Œå¸¸é‡å†…å­˜åè€Œæ›´æ…¢ï¼ˆä¸²è¡ŒåŒ–ï¼‰ã€‚

## å¯„å­˜å™¨ä¼˜åŒ–

### å¯„å­˜å™¨çš„é‡è¦æ€§

å¯„å­˜å™¨æ˜¯æœ€å¿«çš„å­˜å‚¨ï¼Œå•å‘¨æœŸå»¶è¿Ÿã€‚ä½†æ•°é‡æœ‰é™ï¼ˆæ¯ SM çº¦ 64K ä¸ªï¼‰ï¼Œè¿‡åº¦ä½¿ç”¨ä¼šå¯¼è‡´ï¼š

1. **å¯„å­˜å™¨æº¢å‡ºï¼ˆSpillingï¼‰**ï¼šæº¢å‡ºåˆ° Local Memoryï¼ˆå®é™…æ˜¯å…¨å±€å†…å­˜ï¼‰ï¼Œææ…¢
2. **å ç”¨ç‡ä¸‹é™**ï¼šæ¯çº¿ç¨‹ç”¨æ›´å¤šå¯„å­˜å™¨ï¼ŒSM èƒ½å®¹çº³çš„çº¿ç¨‹æ•°å‡å°‘

### æŸ¥çœ‹å¯„å­˜å™¨ä½¿ç”¨

```bash
nvcc --ptxas-options=-v kernel.cu
```

è¾“å‡ºï¼š

```
ptxas info: Used 32 registers, ...
```

### æ§åˆ¶ç­–ç•¥

**ç¼–è¯‘å™¨æç¤º**ï¼š

```cuda
__global__ void __launch_bounds__(256, 4) kernel(...) {
    // å‘Šè¯‰ç¼–è¯‘å™¨ï¼šæ¯ Block 256 çº¿ç¨‹ï¼Œæ¯ SM è‡³å°‘ 4 ä¸ª Block
    // ç¼–è¯‘å™¨æ®æ­¤ä¼˜åŒ–å¯„å­˜å™¨åˆ†é…
}
```

**ç¼–è¯‘é€‰é¡¹**ï¼š

```bash
nvcc -maxrregcount=32 kernel.cu  # é™åˆ¶æ¯çº¿ç¨‹æœ€å¤š 32 ä¸ªå¯„å­˜å™¨
```

**æƒè¡¡**ï¼šé™åˆ¶è¿‡ä¸¥å¯èƒ½å¯¼è‡´æº¢å‡ºï¼Œé™åˆ¶è¿‡æ¾å¯èƒ½é™ä½å ç”¨ç‡ã€‚éœ€è¦å®æµ‹ã€‚

## æ•°æ®å±€éƒ¨æ€§ä¼˜åŒ–æ¸…å•

### ç©ºé—´å±€éƒ¨æ€§

**å®šä¹‰**ï¼šè®¿é—®çš„æ•°æ®åœ¨å†…å­˜ä¸­ç›¸é‚»

**ä¼˜åŒ–æ‰‹æ®µ**ï¼š

- è¿ç»­è®¿é—®ï¼Œåˆ©ç”¨åˆå¹¶
- æ•°æ®å¸ƒå±€ä¼˜åŒ–ï¼ˆAoS â†’ SoAï¼‰

```cuda
// Array of Structuresï¼ˆå·®ï¼‰
struct Particle { float x, y, z; };
Particle particles[N];
particles[i].x;  // è·¨æ­¥ 12 å­—èŠ‚

// Structure of Arraysï¼ˆå¥½ï¼‰
struct Particles { float x[N], y[N], z[N]; };
Particles p;
p.x[i];  // è¿ç»­è®¿é—®
```

### æ—¶é—´å±€éƒ¨æ€§

**å®šä¹‰**ï¼šåŒä¸€æ•°æ®çŸ­æœŸå†…è¢«å¤šæ¬¡è®¿é—®

**ä¼˜åŒ–æ‰‹æ®µ**ï¼š

- Tiling åˆ°å…±äº«å†…å­˜/å¯„å­˜å™¨
- å¾ªç¯åˆ†å—

```cuda
// æ— æ—¶é—´å±€éƒ¨æ€§
for (int k = 0; k < N; k++) {
    C[i][j] += A[i][k] * B[k][j];  // Aã€B æ¯æ¬¡ä»å…¨å±€å†…å­˜è¯»
}

// æœ‰æ—¶é—´å±€éƒ¨æ€§ï¼ˆTiledï¼‰
for (int tile = 0; tile < N/TILE; tile++) {
    // åŠ è½½ tile åˆ°å…±äº«å†…å­˜
    for (int k = 0; k < TILE; k++) {
        C[i][j] += As[ty][k] * Bs[k][tx];  // ä»å…±äº«å†…å­˜è¯»ï¼Œå¤ç”¨
    }
}
```

## å®æˆ˜ï¼šä¼˜åŒ–åçš„çŸ©é˜µä¹˜æ³•æ€§èƒ½

ä»¥ 1024Ã—1024 çŸ©é˜µä¸ºä¾‹ï¼š

| ç‰ˆæœ¬          | å…¨å±€å†…å­˜è®¿é—® | ç®—æœ¯å¼ºåº¦ | ç›¸å¯¹æ€§èƒ½ |
| ------------- | ------------ | -------- | -------- |
| æœ´ç´           | 2Ã—10â¹ æ¬¡     | 0.25     | 1Ã—       |
| Tiled (16Ã—16) | 1.25Ã—10â¸ æ¬¡  | 4        | ~8Ã—      |
| Tiled (32Ã—32) | 6.25Ã—10â· æ¬¡  | 8        | ~12Ã—     |
| + å¯„å­˜å™¨ä¼˜åŒ–  | æ›´å°‘         | 16+      | ~20Ã—     |

å®é™…æå‡å–å†³äºå…·ä½“ GPU å’Œé—®é¢˜è§„æ¨¡ï¼Œä½† 10Ã— ä»¥ä¸Šæ˜¯å¸¸è§çš„ã€‚

## å°ç»“

ç¬¬äº”ç« æ˜¯æ€§èƒ½ä¼˜åŒ–çš„æ ¸å¿ƒï¼š

**å†…å­˜å±‚æ¬¡è®¤çŸ¥**ï¼šå¯„å­˜å™¨â†’å…±äº«å†…å­˜â†’L2â†’å…¨å±€å†…å­˜ï¼Œé€Ÿåº¦å·® 100 å€ä»¥ä¸Šã€‚å†™é«˜æ€§èƒ½ä»£ç å°±æ˜¯è®©çƒ­æ•°æ®ç•™åœ¨å¿«å­˜å‚¨ã€‚

**å…±äº«å†…å­˜æœ¬è´¨**ï¼šç¨‹åºå‘˜å¯æ§çš„ Block çº§ç¼“å­˜ã€‚å£°æ˜ç®€å•ï¼Œä½†éœ€è¦æ­£ç¡®åŒæ­¥ã€‚ä¸¤æ¬¡ __syncthreads() åˆ«å¿˜ã€‚

**Tiling æ ¸å¿ƒ**ï¼šåˆ†å—åŠ è½½ï¼Œå—å†…å¤ç”¨ã€‚çŸ©é˜µä¹˜æ³•ä» 0.25 æå‡åˆ° 8+ FLOP/Byteï¼Œè¿™æ˜¯å®æ‰“å®çš„ 10Ã— åŠ é€Ÿã€‚

**è®¿é—®æ¨¡å¼**ï¼š

- å…¨å±€å†…å­˜è¦åˆå¹¶è®¿é—®
- å…±äº«å†…å­˜è¦é¿å… Bank å†²çª
- å¿…è¦æ—¶ç”¨ Padding

**å±€éƒ¨æ€§åŸåˆ™**ï¼šç©ºé—´å±€éƒ¨æ€§ï¼ˆè¿ç»­è®¿é—®ï¼‰ï¼Œæ—¶é—´å±€éƒ¨æ€§ï¼ˆé‡å¤ä½¿ç”¨ï¼‰ã€‚Tiling åŒæ—¶åˆ©ç”¨äº†ä¸¤è€…ã€‚

æŒæ¡äº†å†…å­˜ä¼˜åŒ–ï¼ŒGPU çš„è®¡ç®—èƒ½åŠ›æ‰èƒ½çœŸæ­£å‘æŒ¥ã€‚ä¸‹ä¸€ç« ä¼šå­¦ä¹ æ›´å¤šè®¡ç®—æ¨¡å¼â€”â€”å·ç§¯ã€è§„çº¦ã€å‰ç¼€å’Œï¼Œè¿™äº›éƒ½éœ€è¦ç²¾å¿ƒè®¾è®¡çš„å†…å­˜è®¿é—®ç­–ç•¥ã€‚

---

**å‚è€ƒèµ„æ–™ï¼š**

- Hwu, W., Kirk, D., & El Hajj, I. (2022). *Programming Massively Parallel Processors: A Hands-on Approach* (4th Edition). Morgan Kaufmann.
- [CUDA C++ Programming Guide - Memory Model](https://docs.nvidia.com/cuda/cuda-c-programming-guide/index.html#memory-hierarchy)
- [CUDA Best Practices Guide](https://docs.nvidia.com/cuda/cuda-c-best-practices-guide/)

---

> **æœ¬æ–‡ GitHub ä»“åº“**: [https://github.com/psmarter/PMPP-Learning](https://github.com/psmarter/PMPP-Learning)
