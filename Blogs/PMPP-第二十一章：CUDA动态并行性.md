---
title: PMPP-ç¬¬äºŒåä¸€ç« ï¼šCUDAåŠ¨æ€å¹¶è¡Œæ€§
date: 2026-01-24 16:20:44
tags:
  - CUDA
  - GPUç¼–ç¨‹
  - å¹¶è¡Œè®¡ç®—
  - PMPP
  - åŠ¨æ€å¹¶è¡Œ
  - é€’å½’ç®—æ³•
  - å››å‰æ ‘
categories: çŸ¥è¯†åˆ†äº«
cover: /img/PMPP.jpg
---

## å‰è¨€

ç¬¬äºŒåç« ä»‹ç»äº†å¤š GPU é›†ç¾¤ç¼–ç¨‹ã€‚ç¬¬äºŒåä¸€ç« å›åˆ°å• GPU çš„é«˜çº§ç‰¹æ€§â€”â€”**åŠ¨æ€å¹¶è¡Œæ€§ï¼ˆDynamic Parallelismï¼‰**ã€‚ä¼ ç»Ÿ CUDA ç¨‹åºä¸­ï¼Œåªæœ‰ CPU èƒ½å¯åŠ¨æ ¸å‡½æ•°ï¼›è€ŒåŠ¨æ€å¹¶è¡Œæ€§å…è®¸**GPU æ ¸å‡½æ•°ç›´æ¥å¯åŠ¨å­æ ¸å‡½æ•°**ï¼Œæ— éœ€è¿”å› CPUã€‚è¿™ä¸€ç‰¹æ€§å¯¹é€’å½’ç®—æ³•ã€è‡ªé€‚åº”è®¡ç®—ã€ä¸è§„åˆ™æ•°æ®ç»“æ„ï¼ˆå¦‚æ ‘ã€å›¾ï¼‰çš„å¤„ç†ç‰¹åˆ«æœ‰ç”¨ã€‚

> **ğŸ“¦ é…å¥—èµ„æº**ï¼šæœ¬ç³»åˆ—æ–‡ç« é…æœ‰å®Œæ•´çš„ [GitHub ä»“åº“](https://github.com/psmarter/PMPP-Learning)ï¼ŒåŒ…å«æ¯ç« çš„ç»ƒä¹ é¢˜è§£ç­”ã€CUDA ä»£ç å®ç°å’Œè¯¦ç»†æ³¨é‡Šã€‚æ‰€æœ‰ä»£ç éƒ½ç»è¿‡æµ‹è¯•ï¼Œå¯ä»¥ç›´æ¥è¿è¡Œã€‚

## ä»€ä¹ˆæ˜¯åŠ¨æ€å¹¶è¡Œæ€§

### ä¼ ç»Ÿ CUDA æ¨¡å‹çš„é™åˆ¶

ä¼ ç»Ÿ CUDA ç¨‹åºä¸­ï¼š

```
CPU ä»£ç  â†’ å¯åŠ¨ kernel1 â†’ GPU æ‰§è¡Œ â†’ è¿”å› CPU
         â†’ å¯åŠ¨ kernel2 â†’ GPU æ‰§è¡Œ â†’ è¿”å› CPU
         â†’ ...
```

**é—®é¢˜**ï¼š

1. æ¯æ¬¡å¯åŠ¨ kernel éƒ½éœ€è¦ CPU å‚ä¸
2. é€’å½’ç®—æ³•éš¾ä»¥è¡¨è¾¾
3. è‡ªé€‚åº”ç®—æ³•éœ€è¦å¤šæ¬¡ CPU-GPU å¾€è¿”

### åŠ¨æ€å¹¶è¡Œæ€§

**åŠ¨æ€å¹¶è¡Œæ€§**ï¼šå…è®¸ GPU kernel ç›´æ¥å¯åŠ¨å­ kernelï¼ˆchild kernelï¼‰ã€‚

```
CPU ä»£ç  â†’ å¯åŠ¨çˆ¶ kernel â†’ GPU æ‰§è¡Œ
                           â”œâ†’ å¯åŠ¨å­ kernel1 â†’ GPU æ‰§è¡Œ
                           â”œâ†’ å¯åŠ¨å­ kernel2 â†’ GPU æ‰§è¡Œ
                           â””â†’ ...
```

**ä¼˜åŠ¿**ï¼š

- å‡å°‘ CPU-GPU é€šä¿¡
- è‡ªç„¶è¡¨è¾¾é€’å½’ç®—æ³•
- æ ¹æ®æ•°æ®ç‰¹æ€§åŠ¨æ€è°ƒæ•´è®¡ç®—

### ç¡¬ä»¶è¦æ±‚

åŠ¨æ€å¹¶è¡Œæ€§éœ€è¦è®¡ç®—èƒ½åŠ› 3.5 æˆ–æ›´é«˜çš„ GPUã€‚

```bash
# ç¼–è¯‘æ—¶éœ€è¦ç‰¹æ®Šé€‰é¡¹
nvcc -arch=sm_35 -rdc=true my_program.cu -lcudadevrt
```

- `-rdc=true`ï¼šå¯ç”¨å¯é‡å®šä½è®¾å¤‡ä»£ç 
- `-lcudadevrt`ï¼šé“¾æ¥è®¾å¤‡è¿è¡Œæ—¶åº“

## åŸºæœ¬è¯­æ³•

### åœ¨è®¾å¤‡ä»£ç ä¸­å¯åŠ¨ kernel

```cuda
__global__ void child_kernel(int *data, int n) {
    int idx = threadIdx.x + blockIdx.x * blockDim.x;
    if (idx < n) {
        data[idx] *= 2;
    }
}

__global__ void parent_kernel(int *data, int n) {
    // åœ¨è®¾å¤‡ä»£ç ä¸­å¯åŠ¨å­ kernel
    child_kernel<<<1, 32>>>(data, n);
    
    // ç­‰å¾…å­ kernel å®Œæˆ
    cudaDeviceSynchronize();
}
```

### è®¾å¤‡ç«¯åŒæ­¥

```cuda
// ç­‰å¾…å½“å‰çº¿ç¨‹å¯åŠ¨çš„æ‰€æœ‰å­ kernel å®Œæˆ
cudaDeviceSynchronize();

// ç­‰å¾…ç‰¹å®šæµä¸­çš„æ“ä½œå®Œæˆ
cudaStreamSynchronize(stream);
```

**æ³¨æ„**ï¼šçˆ¶ kernel é€€å‡ºæ—¶ä¼šéšå¼ç­‰å¾…æ‰€æœ‰å­ kernel å®Œæˆã€‚

### è®¾å¤‡ç«¯å†…å­˜ç®¡ç†

```cuda
__global__ void parent_kernel() {
    float *temp;
    
    // åœ¨è®¾å¤‡ç«¯åˆ†é…å†…å­˜
    cudaMalloc(&temp, 1024 * sizeof(float));
    
    // ä½¿ç”¨å†…å­˜...
    child_kernel<<<1, 256>>>(temp, 1024);
    cudaDeviceSynchronize();
    
    // é‡Šæ”¾å†…å­˜
    cudaFree(temp);
}
```

## å†…å­˜å¯è§æ€§

### å“ªäº›å†…å­˜å­ kernel å¯ä»¥è®¿é—®

| å†…å­˜ç±»å‹ | å­ kernel å¯è®¿é—® | è¯´æ˜             |
| -------- | ---------------- | ---------------- |
| å…¨å±€å†…å­˜ | âœ“                | çˆ¶å­å…±äº«         |
| å¸¸é‡å†…å­˜ | âœ“                | ç¼–è¯‘æ—¶ç¡®å®šï¼Œå…±äº« |
| çº¹ç†å†…å­˜ | âœ“                | çˆ¶å­å…±äº«         |
| å…±äº«å†…å­˜ | âœ—                | ä»…é™å½“å‰ Block   |
| å±€éƒ¨å†…å­˜ | âœ—                | ä»…é™å½“å‰çº¿ç¨‹     |

### å†…å­˜ä¸€è‡´æ€§

çˆ¶ kernel çš„å…¨å±€å†…å­˜å†™å…¥å¯¹å­ kernel å¯è§ï¼Œéœ€è¦éµå¾ªä¸€å®šè§„åˆ™ï¼š

```cuda
__global__ void parent_kernel(int *data) {
    // å†™å…¥å…¨å±€å†…å­˜
    data[threadIdx.x] = threadIdx.x * 2;
    
    // ç¡®ä¿å†™å…¥å®Œæˆï¼ˆå—å†…åŒæ­¥ï¼‰
    __threadfence();
    
    // å¯åŠ¨å­ kernel
    if (threadIdx.x == 0) {
        child_kernel<<<1, 32>>>(data);
    }
}
```

**å…³é”®ç‚¹**ï¼š

- çˆ¶çº¿ç¨‹åœ¨å¯åŠ¨å­ kernel å‰çš„å†™å…¥å¯¹å­ kernel å¯è§
- å­ kernel çš„å†™å…¥åœ¨ `cudaDeviceSynchronize()` åå¯¹çˆ¶çº¿ç¨‹å¯è§

## æµä¸å¹¶å‘

### é»˜è®¤æµè¡Œä¸º

```cuda
__global__ void parent_kernel() {
    // è¿™ä¸¤ä¸ª kernel åœ¨åŒä¸€ä¸ª Block çš„é»˜è®¤æµä¸­é¡ºåºæ‰§è¡Œ
    child_kernel1<<<1, 32>>>();
    child_kernel2<<<1, 32>>>();  // ç­‰å¾… child_kernel1 å®Œæˆ
}
```

**é‡è¦**ï¼šåŒä¸€ Block å†…çš„çº¿ç¨‹å…±äº«é»˜è®¤æµï¼Œå› æ­¤å­ kernel ä¼šä¸²è¡Œæ‰§è¡Œã€‚

### ä½¿ç”¨ç‹¬ç«‹æµå®ç°å¹¶å‘

```cuda
__global__ void parent_kernel() {
    cudaStream_t stream;
    cudaStreamCreateWithFlags(&stream, cudaStreamNonBlocking);
    
    // åœ¨ç‹¬ç«‹æµä¸­å¯åŠ¨ï¼Œå¯ä»¥ä¸å…¶ä»– kernel å¹¶å‘
    child_kernel<<<1, 32, 0, stream>>>();
    
    cudaStreamDestroy(stream);
}
```

### å¹¶å‘å­ kernel ç¤ºä¾‹

```cuda
__global__ void parent_kernel(float *data, int n) {
    int chunk_size = n / 4;
    cudaStream_t streams[4];
    
    for (int i = 0; i < 4; i++) {
        cudaStreamCreateWithFlags(&streams[i], cudaStreamNonBlocking);
        child_kernel<<<1, 256, 0, streams[i]>>>(
            data + i * chunk_size, chunk_size);
    }
    
    // ç­‰å¾…æ‰€æœ‰æµå®Œæˆ
    cudaDeviceSynchronize();
    
    for (int i = 0; i < 4; i++) {
        cudaStreamDestroy(streams[i]);
    }
}
```

## å¯åŠ¨æ± é…ç½®

### ä»€ä¹ˆæ˜¯å¯åŠ¨æ± 

æ¯æ¬¡å­ kernel å¯åŠ¨éœ€è¦ä»**å¯åŠ¨æ± **åˆ†é…èµ„æºã€‚

**ä¸¤ç§æ± **ï¼š

1. **å›ºå®šå¤§å°æ± **ï¼šé»˜è®¤ 2048 ä¸ªæ§½ä½ï¼Œé¢„åˆ†é…
2. **è™šæ‹ŸåŒ–æ± **ï¼šåŠ¨æ€æ‰©å±•ï¼Œä½†æ€§èƒ½è¾ƒä½

### é…ç½®å¯åŠ¨æ± 

```cuda
// è·å–å½“å‰è®¾å¤‡å±æ€§
cudaDeviceProp prop;
cudaGetDeviceProperties(&prop, 0);

// è®¾ç½®å›ºå®šæ± å¤§å°
cudaDeviceSetLimit(cudaLimitDevRuntimePendingLaunchCount, 8192);
```

**å»ºè®®**ï¼š

- å¦‚æœé¢„æœŸå­ kernel æ•°é‡è¶…è¿‡é»˜è®¤å€¼ï¼Œå¢å¤§å›ºå®šæ± 
- å¦‚æœå­ kernel æ•°é‡å¯é¢„æµ‹ï¼Œè®¾ç½®ä¸ºè¯¥å€¼

## åº”ç”¨ç¤ºä¾‹ï¼šBezier æ›²çº¿ç»†åˆ†

### é—®é¢˜æè¿°

Bezier æ›²çº¿ç”±æ§åˆ¶ç‚¹å®šä¹‰ã€‚æ›²çº¿è¶Šå¼¯æ›²ï¼Œéœ€è¦è¶Šå¤šé‡‡æ ·ç‚¹æ‰èƒ½å¹³æ»‘æ˜¾ç¤ºã€‚

**è‡ªé€‚åº”ç»†åˆ†**ï¼šæ ¹æ®æ›²ç‡å†³å®šé‡‡æ ·ç‚¹æ•°é‡ã€‚

### æ•°æ®ç»“æ„

```cuda
#define MAX_TESS_POINTS 32

struct BezierLine {
    float2 CP[3];                      // 3 ä¸ªæ§åˆ¶ç‚¹
    float2 vertexPos[MAX_TESS_POINTS]; // ç»†åˆ†åçš„é¡¶ç‚¹
    int nVertices;                     // é¡¶ç‚¹æ•°é‡
};
```

### è®¡ç®—æ›²ç‡

```cuda
__device__ float computeCurvature(float2 *cp) {
    // è®¡ç®—é¦–å°¾è¿çº¿é•¿åº¦
    float dx = cp[2].x - cp[0].x;
    float dy = cp[2].y - cp[0].y;
    float line_length = sqrtf(dx * dx + dy * dy);
    
    if (line_length < 0.001f) return 0.0f;
    
    // è®¡ç®—ä¸­ç‚¹åˆ°ç›´çº¿çš„è·ç¦»ï¼ˆæ›²ç‡è¿‘ä¼¼ï¼‰
    float cross = fabsf((cp[1].x - cp[0].x) * dy - 
                        (cp[1].y - cp[0].y) * dx);
    return cross / line_length;
}
```

### å­ kernelï¼šè®¡ç®—ç»†åˆ†ç‚¹

```cuda
__global__ void computeBezierLine_child(
    int lidx, BezierLine *bLines, int nTessPoints) {
    
    int idx = threadIdx.x + blockDim.x * blockIdx.x;
    if (idx < nTessPoints) {
        // è®¡ç®—å‚æ•° u âˆˆ [0, 1]
        float u = (float)idx / (float)(nTessPoints - 1);
        float omu = 1.0f - u;
        
        // äºŒæ¬¡ Bezier åŸºå‡½æ•°
        float B[3];
        B[0] = omu * omu;
        B[1] = 2.0f * u * omu;
        B[2] = u * u;
        
        // è®¡ç®—ç‚¹ä½ç½®
        float2 pos = {0, 0};
        for (int i = 0; i < 3; i++) {
            pos.x += B[i] * bLines[lidx].CP[i].x;
            pos.y += B[i] * bLines[lidx].CP[i].y;
        }
        
        bLines[lidx].vertexPos[idx] = pos;
    }
}
```

### çˆ¶ kernelï¼šåŠ¨æ€å†³å®šç»†åˆ†ç¨‹åº¦

```cuda
__global__ void computeBezierLines_parent(
    BezierLine *bLines, int nLines) {
    
    int lidx = threadIdx.x + blockDim.x * blockIdx.x;
    if (lidx < nLines) {
        // æ ¹æ®æ›²ç‡è®¡ç®—éœ€è¦çš„é¡¶ç‚¹æ•°
        float curvature = computeCurvature(bLines[lidx].CP);
        int nVertices = min(max((int)(curvature * 16.0f), 4), 
                            MAX_TESS_POINTS);
        bLines[lidx].nVertices = nVertices;
        
        // åŠ¨æ€å¯åŠ¨å­ kernel
        int blocks = (nVertices + 31) / 32;
        computeBezierLine_child<<<blocks, 32>>>(
            lidx, bLines, nVertices);
    }
}
```

### åŠ¨æ€ vs é™æ€å¯¹æ¯”

```cuda
// é™æ€ç‰ˆæœ¬ï¼šæ¯æ¡æ›²çº¿ä½¿ç”¨å›ºå®š Blockï¼Œå¾ªç¯å¤„ç†
__global__ void computeBezierLines_static(
    BezierLine *bLines, int nLines) {
    
    int bidx = blockIdx.x;
    if (bidx < nLines) {
        float curvature = computeCurvature(bLines[bidx].CP);
        int nVertices = min(max((int)(curvature * 16.0f), 4), 
                            MAX_TESS_POINTS);
        bLines[bidx].nVertices = nVertices;
        
        // ç”¨å¾ªç¯ä»£æ›¿å­ kernel
        for (int inc = 0; inc < nVertices; inc += blockDim.x) {
            int idx = inc + threadIdx.x;
            if (idx < nVertices) {
                // ... è®¡ç®—é¡¶ç‚¹ ...
            }
        }
    }
}
```

**å¯¹æ¯”**ï¼š

| æ–¹é¢     | åŠ¨æ€å¹¶è¡Œ           | é™æ€ç‰ˆæœ¬     |
| -------- | ------------------ | ------------ |
| ä»£ç ç»“æ„ | æ›´è‡ªç„¶             | éœ€è¦æ‰‹åŠ¨å¾ªç¯ |
| èµ„æºåˆ©ç”¨ | å­ kernel ç²¾ç¡®é…ç½® | å¯èƒ½æµªè´¹çº¿ç¨‹ |
| å¯åŠ¨å¼€é”€ | è¾ƒé«˜               | æ— é¢å¤–å¼€é”€   |
| é€‚ç”¨åœºæ™¯ | å·¥ä½œé‡å˜åŒ–å¤§       | å·¥ä½œé‡å‡åŒ€   |

## åº”ç”¨ç¤ºä¾‹ï¼šå››å‰æ ‘æ„å»º

### é—®é¢˜æè¿°

**å››å‰æ ‘ï¼ˆQuadtreeï¼‰**ï¼šé€’å½’åœ°å°† 2D ç©ºé—´åˆ’åˆ†ä¸ºå››ä¸ªè±¡é™ï¼Œç”¨äºç©ºé—´ç´¢å¼•ã€ç¢°æ’æ£€æµ‹ã€å›¾åƒå‹ç¼©ç­‰ã€‚

```
åˆå§‹åŒºåŸŸ         ç¬¬ä¸€æ¬¡åˆ’åˆ†         ç»§ç»­åˆ’åˆ†...
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”     â”Œâ”€â”€â”€â”€â”¬â”€â”€â”€â”€â”     â”Œâ”€â”€â”¬â”€â”€â”¬â”€â”€â”€â”€â”
â”‚         â”‚     â”‚ TL â”‚ TR â”‚     â”‚  â”‚  â”‚ TR â”‚
â”‚    *    â”‚  â†’  â”œâ”€â”€â”€â”€â”¼â”€â”€â”€â”€â”¤  â†’  â”œâ”€â”€â”¼â”€â”€â”¼â”€â”€â”€â”€â”¤
â”‚   **    â”‚     â”‚ BL â”‚ BR â”‚     â”‚  â”‚  â”‚    â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜     â””â”€â”€â”€â”€â”´â”€â”€â”€â”€â”˜     â””â”€â”€â”´â”€â”€â”´â”€â”€â”€â”€â”˜
```

### é€’å½’ç®—æ³•

```
function build_quadtree(node, points):
    if depth > max_depth or len(points) < threshold:
        return  // åœæ­¢é€’å½’
    
    // å°†ç‚¹åˆ†ç±»åˆ°å››ä¸ªè±¡é™
    for each point in points:
        classify to TL, TR, BL, or BR
    
    // é€’å½’å¤„ç†æ¯ä¸ªè±¡é™
    build_quadtree(node.TL, TL_points)
    build_quadtree(node.TR, TR_points)
    build_quadtree(node.BL, BL_points)
    build_quadtree(node.BR, BR_points)
```

### æ•°æ®ç»“æ„

```cuda
class Quadtree_node {
    int m_id;                  // èŠ‚ç‚¹ ID
    Bounding_box m_bbox;       // è¾¹ç•Œæ¡†
    int m_begin, m_end;        // ç‚¹èŒƒå›´ [begin, end)
    
public:
    __device__ int num_points() const { return m_end - m_begin; }
    // ...
};

struct Parameters {
    int point_selector;         // åŒç¼“å†²é€‰æ‹©å™¨
    int num_nodes_at_this_level; // å½“å‰å±‚èŠ‚ç‚¹æ•°
    int depth;                  // å½“å‰æ·±åº¦
    int max_depth;              // æœ€å¤§æ·±åº¦
    int min_points_per_node;    // åœæ­¢é˜ˆå€¼
};
```

### æ ¸å¿ƒ kernel

```cuda
__global__ void build_quadtree_kernel(
    Quadtree_node *nodes, Points *points, Parameters params) {
    
    __shared__ int smem[8];  // æ¯ä¸ªè±¡é™çš„ç‚¹æ•°å’Œåç§»
    
    Quadtree_node *node = &nodes[blockIdx.x];
    int num_points = node->num_points();
    
    // æ£€æŸ¥åœæ­¢æ¡ä»¶
    if (params.depth >= params.max_depth || 
        num_points <= params.min_points_per_node) {
        return;
    }
    
    // è®¡ç®—è¾¹ç•Œæ¡†ä¸­å¿ƒ
    float2 center;
    node->bounding_box().compute_center(&center);
    
    // ç»Ÿè®¡æ¯ä¸ªè±¡é™çš„ç‚¹æ•°
    count_points_in_children(points[params.point_selector], 
                              smem, node, center);
    
    // è®¡ç®—é‡æ’åç§»
    scan_for_offsets(node->points_begin(), smem);
    
    // é‡æ’ç‚¹åˆ°åŒç¼“å†²
    reorder_points(points[(params.point_selector + 1) % 2],
                   points[params.point_selector], smem, node, center);
    
    // é€’å½’å¯åŠ¨å­ kernel
    if (threadIdx.x == 0) {
        Quadtree_node *children = 
            &nodes[params.num_nodes_at_this_level + blockIdx.x * 4];
        
        prepare_children(children, node, smem, center);
        
        Parameters next_params(params, true);  // æ›´æ–°å‚æ•°
        
        for (int i = 0; i < 4; i++) {
            if (smem[i] > 0) {  // åªå¤„ç†éç©ºè±¡é™
                build_quadtree_kernel<<<1, 32>>>(
                    &children[i], points, next_params);
            }
        }
    }
}
```

### ç‚¹åˆ†ç±»ï¼ˆç»Ÿè®¡é˜¶æ®µï¼‰

```cuda
__device__ void count_points_in_children(
    const Points &in_points, int *smem, 
    int range_begin, int range_end, float2 center) {
    
    // åˆå§‹åŒ–è®¡æ•°
    if (threadIdx.x < 4) {
        smem[threadIdx.x] = 0;
    }
    __syncthreads();
    
    // æ¯ä¸ªçº¿ç¨‹å¤„ç†å¤šä¸ªç‚¹
    for (int iter = range_begin + threadIdx.x; 
         iter < range_end; iter += blockDim.x) {
        float2 p = in_points.get_point(iter);
        
        if (p.x < center.x && p.y >= center.y) {
            atomicAdd(&smem[0], 1);  // å·¦ä¸Š
        } else if (p.x >= center.x && p.y >= center.y) {
            atomicAdd(&smem[1], 1);  // å³ä¸Š
        } else if (p.x < center.x && p.y < center.y) {
            atomicAdd(&smem[2], 1);  // å·¦ä¸‹
        } else {
            atomicAdd(&smem[3], 1);  // å³ä¸‹
        }
    }
    __syncthreads();
}
```

### æ·±åº¦åˆ†æ

å‡è®¾åˆå§‹æœ‰ 64 ä¸ªå‡åŒ€åˆ†å¸ƒçš„ç‚¹ï¼š

| æ·±åº¦ | èŠ‚ç‚¹æ•° | æ¯èŠ‚ç‚¹ç‚¹æ•° |
| ---- | ------ | ---------- |
| 0    | 1      | 64         |
| 1    | 4      | 16         |
| 2    | 16     | 4          |
| 3    | 64     | 1          |

æ€»å…±å¯åŠ¨ 1 + 4 + 16 = **21** ä¸ªå­ kernelã€‚

## æ€§èƒ½è€ƒè™‘

### å¯åŠ¨å¼€é”€

å­ kernel å¯åŠ¨æœ‰å¼€é”€ï¼š

- èµ„æºåˆ†é…
- å‚æ•°ä¼ é€’
- è°ƒåº¦å»¶è¿Ÿ

**å»ºè®®**ï¼šåªåœ¨å·¥ä½œé‡è¶³å¤Ÿå¤§æ—¶ä½¿ç”¨åŠ¨æ€å¹¶è¡Œã€‚

### åµŒå¥—æ·±åº¦é™åˆ¶

CUDA é™åˆ¶åµŒå¥—æ·±åº¦ï¼ˆé€šå¸¸ 24 å±‚ï¼‰ã€‚

```cuda
// æ£€æŸ¥æ”¯æŒçš„åµŒå¥—æ·±åº¦
int max_depth;
cudaDeviceGetAttribute(&max_depth, 
    cudaDevAttrMaxDeviceRuntimeSynchronizationDepth, 0);
```

### å†…å­˜æ¶ˆè€—

æ¯å±‚é€’å½’æ¶ˆè€—æ ˆç©ºé—´ã€‚æ·±åº¦é€’å½’å¯èƒ½å¯¼è‡´æ ˆæº¢å‡ºã€‚

```cuda
// å¢å¤§æ ˆå¤§å°
cudaDeviceSetLimit(cudaLimitStackSize, 8192);
```

### ä½•æ—¶ä½¿ç”¨åŠ¨æ€å¹¶è¡Œ

**é€‚åˆä½¿ç”¨**ï¼š

- é€’å½’ç®—æ³•ï¼ˆæ ‘éå†ã€åˆ†æ²»ï¼‰
- è‡ªé€‚åº”ç»†åˆ†ï¼ˆç½‘æ ¼ç»†åŒ–ã€LODï¼‰
- ä¸è§„åˆ™æ•°æ®ï¼ˆç¨€ç–å›¾ã€ä¸å¹³è¡¡æ ‘ï¼‰

**ä¸é€‚åˆä½¿ç”¨**ï¼š

- è§„åˆ™çš„æ•°æ®å¹¶è¡Œï¼ˆçŸ©é˜µè¿ç®—ï¼‰
- å­ kernel å·¥ä½œé‡å¾ˆå°
- éœ€è¦æè‡´æ€§èƒ½çš„åœºæ™¯

## è°ƒè¯•ä¸æœ€ä½³å®è·µ

### é”™è¯¯å¤„ç†

```cuda
__global__ void parent_kernel() {
    cudaError_t err;
    
    child_kernel<<<1, 32>>>();
    err = cudaGetLastError();
    if (err != cudaSuccess) {
        printf("Child kernel launch failed: %s\n", 
               cudaGetErrorString(err));
    }
    
    err = cudaDeviceSynchronize();
    if (err != cudaSuccess) {
        printf("Child kernel execution failed: %s\n", 
               cudaGetErrorString(err));
    }
}
```

### é¿å…è¿‡åº¦åµŒå¥—

```cuda
__global__ void recursive_kernel(int depth, int max_depth) {
    if (depth >= max_depth) {
        return;  // åœæ­¢é€’å½’
    }
    
    recursive_kernel<<<1, 32>>>(depth + 1, max_depth);
}
```

### èµ„æºç®¡ç†

```cuda
__global__ void parent_kernel() {
    float *temp;
    cudaMalloc(&temp, size);
    
    // ç¡®ä¿å­ kernel å®Œæˆåå†é‡Šæ”¾
    child_kernel<<<1, 32>>>(temp);
    cudaDeviceSynchronize();
    
    cudaFree(temp);
}
```

## å°ç»“

ç¬¬äºŒåä¸€ç« ä»‹ç»äº† CUDA åŠ¨æ€å¹¶è¡Œæ€§è¿™ä¸€é«˜çº§ç‰¹æ€§ï¼š

**æ ¸å¿ƒæ¦‚å¿µ**ï¼šGPU kernel å¯ä»¥ç›´æ¥å¯åŠ¨å­ kernelï¼Œæ— éœ€è¿”å› CPUã€‚è¿™ä½¿å¾—é€’å½’ç®—æ³•å’Œè‡ªé€‚åº”è®¡ç®—å¯ä»¥å®Œå…¨åœ¨ GPU ä¸Šæ‰§è¡Œã€‚

**è¯­æ³•è¦ç‚¹**ï¼š

- åœ¨ `__global__` å‡½æ•°ä¸­ä½¿ç”¨ `<<<...>>>` å¯åŠ¨å­ kernel
- `cudaDeviceSynchronize()` ç­‰å¾…å­ kernel å®Œæˆ
- å¯ä»¥åœ¨è®¾å¤‡ç«¯ä½¿ç”¨ `cudaMalloc`/`cudaFree`

**å†…å­˜å¯è§æ€§**ï¼š

- å…¨å±€ã€å¸¸é‡ã€çº¹ç†å†…å­˜çˆ¶å­å…±äº«
- å…±äº«å†…å­˜å’Œå±€éƒ¨å†…å­˜ä¸èƒ½ä¼ é€’ç»™å­ kernel

**æµä¸å¹¶å‘**ï¼š

- åŒä¸€ Block çš„é»˜è®¤æµå…±äº«ï¼Œå­ kernel ä¸²è¡Œæ‰§è¡Œ
- ä½¿ç”¨éé˜»å¡æµå®ç°å­ kernel å¹¶å‘

**åº”ç”¨åœºæ™¯**ï¼š

- Bezier æ›²çº¿è‡ªé€‚åº”ç»†åˆ†ï¼šæ ¹æ®æ›²ç‡åŠ¨æ€å†³å®šé‡‡æ ·å¯†åº¦
- å››å‰æ ‘æ„å»ºï¼šé€’å½’åˆ’åˆ†ç©ºé—´

**æ€§èƒ½è€ƒè™‘**ï¼š

- å¯åŠ¨å¼€é”€ä¸å¯å¿½è§†
- æ·±åº¦é€’å½’æ¶ˆè€—æ ˆç©ºé—´
- é…ç½®å¯åŠ¨æ± å¤§å°

åŠ¨æ€å¹¶è¡Œæ€§è®© GPU ç¼–ç¨‹æ›´åŠ çµæ´»ï¼Œä½†è¦æƒè¡¡ä½¿ç”¨â€”â€”å¯¹äºè§„åˆ™çš„æ•°æ®å¹¶è¡Œä»»åŠ¡ï¼Œä¼ ç»Ÿæ–¹å¼å¯èƒ½æ›´é«˜æ•ˆã€‚å¯¹äºå¤©ç„¶é€’å½’æˆ–è‡ªé€‚åº”çš„é—®é¢˜ï¼ŒåŠ¨æ€å¹¶è¡Œæ€§æ˜¯å¼ºå¤§çš„å·¥å…·ã€‚

## ğŸš€ ä¸‹ä¸€æ­¥

- å®ç° Bezier æ›²çº¿çš„è‡ªé€‚åº”ç»†åˆ†ï¼Œä½“éªŒåŠ¨æ€å¹¶è¡Œæ€§çš„ä¼˜åŠ¿
- æ„å»ºä¸€ä¸ªå››å‰æ ‘æˆ–å…«å‰æ ‘ï¼Œå­¦ä¹ é€’å½’ç®—æ³•çš„ GPU å®ç°
- æ¢ç´¢å…¶ä»–é€’å½’ç®—æ³•ï¼šå¿«é€Ÿæ’åºã€å½’å¹¶æ’åºã€åˆ†æ²»ç®—æ³•
- å­¦ä¹ åŠ¨æ€å¹¶è¡Œæ€§çš„æ€§èƒ½è°ƒä¼˜ï¼šå¯åŠ¨æ± é…ç½®ã€åµŒå¥—æ·±åº¦æ§åˆ¶
- å¯¹æ¯”åŠ¨æ€å¹¶è¡Œæ€§ä¸ä¼ ç»Ÿæ–¹æ³•çš„æ€§èƒ½å·®å¼‚ï¼Œç†è§£é€‚ç”¨åœºæ™¯
- ç ”ç©¶è‡ªé€‚åº”ç½‘æ ¼ç»†åŒ–ï¼ˆAMRï¼‰ç­‰é«˜çº§åº”ç”¨

---

## ğŸ“š å‚è€ƒèµ„æ–™

- PMPP ç¬¬å››ç‰ˆ Chapter 21
- [ç¬¬äºŒåä¸€ç« ï¼šCUDAåŠ¨æ€å¹¶è¡Œæ€§](https://smarter.xin/posts/pmmpp-chapter21-dynamic-parallelism/)
- Hwu, W., Kirk, D., & El Hajj, I. (2022). *Programming Massively Parallel Processors: A Hands-on Approach* (4th Edition). Morgan Kaufmann.
- NVIDIA. *CUDA C++ Programming Guide - Dynamic Parallelism*. <https://docs.nvidia.com/cuda/cuda-c-programming-guide/>
- NVIDIA. *CUDA Dynamic Parallelism*. <https://developer.nvidia.com/blog/cuda-dynamic-parallelism-api-principles/>

**å­¦ä¹ æ„‰å¿«ï¼** ğŸ“

---

> **æœ¬æ–‡ GitHub ä»“åº“**: [https://github.com/psmarter/PMPP-Learning](https://github.com/psmarter/PMPP-Learning)
